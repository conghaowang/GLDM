{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5caa28ca",
   "metadata": {},
   "source": [
    "# Design \n",
    "\n",
    "1. All model related loss computations and helper functions are in torch.modules and they will all be called compute_loss \n",
    "2. The MLPDecoder will house all the MLPs involved in the decoder and will have 1 compute_decoder_loss_method that will call all the individual compute_loss methods.\n",
    "\n",
    "It will also have a decode method that will do decoding at inference time(TODO)\n",
    "\n",
    "3. The FullGraphEncoder and the PartialGraphEncoder will each be in their own torch modules\n",
    "\n",
    "4. Finally, the lightning module will have 3 things: \n",
    "- FullGraphEncoder\n",
    "- PartialGraphEncoder (part of decoder)\n",
    "- MLPDecoder\n",
    "\n",
    "And after passing through the initial FullGraphEncoder, if we are working with a VAE, we will extract p and q for computing the kl divergence loss, otherwise we will do the other model specific stuff like diffusion.\n",
    "\n",
    "`params` dictionary will be passed to the lightning module and each torch module will be constructed within it using the relevant parameters by destructuring the dictionary \n",
    "\n",
    "node type class weights will be instantiated in the lightning module and passed to the decoder\n",
    "\n",
    "# TODO\n",
    "1. fix the incrementing in the original graph edge index (DONE)\n",
    "2. Work on first node prediction \n",
    "3. Investigate node_type_predictor_class_loss_weight_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params houses all relevant model instantiation parameters\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75459146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import MolerDataset, MolerData\n",
    "from utils import pprint_pyg_obj\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50a5acbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = MolerDataset(\n",
    "    root = '/data/ongh0068', \n",
    "    raw_moler_trace_dataset_parent_folder = '/data/ongh0068/guacamol/trace_dir',\n",
    "    output_pyg_trace_dataset_parent_folder = '/data/ongh0068/l1000/already_batched',\n",
    "    split = 'train_0',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b80108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, follow_batch = [\n",
    "    'correct_edge_choices',\n",
    "    'correct_edge_types',\n",
    "    'valid_edge_choices',\n",
    "    'valid_attachment_point_choices',\n",
    "    'correct_attachment_point_choice',\n",
    "    'correct_node_type_choices',\n",
    "    'original_graph_x',\n",
    "    'correct_first_node_type_choices'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "340217e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea61240",
   "metadata": {},
   "source": [
    "# FullGraphEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericGraphEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59373d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(torch.nn.Module):\n",
    "    \"\"\"Returns graph level representation of the molecules.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_feature_dim,\n",
    "        atom_or_motif_vocab_size,\n",
    "        motif_embedding_size = 64,\n",
    "        hidden_layer_feature_dim=64,\n",
    "        num_layers=12,\n",
    "        layer_type=\"RGATConv\",\n",
    "        use_intermediate_gnn_results=True,\n",
    "    ):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self._embed = torch.nn.Embedding(atom_or_motif_vocab_size, motif_embedding_size)\n",
    "        self._model = GenericGraphEncoder(input_feature_dim = motif_embedding_size + input_feature_dim)\n",
    "        \n",
    "    def forward(self, original_graph_node_categorical_features, node_features, edge_index, edge_type, batch_index):\n",
    "        motif_embeddings = self._embed(original_graph_node_categorical_features)\n",
    "        node_features = torch.cat((node_features, motif_embeddings), axis = -1)\n",
    "        input_molecule_representations, _ = self._model(node_features, edge_index.long(), edge_type, batch_index)\n",
    "        return input_molecule_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['full_graph_encoder'] = {\n",
    "    'input_feature_dim': batch.x.shape[-1],\n",
    "    'atom_or_motif_vocab_size': len(dataset.node_type_index_to_string)\n",
    "}\n",
    "\n",
    "full_graph_encoder = GraphEncoder(\n",
    "    input_feature_dim = batch.x.shape[-1],\n",
    "    atom_or_motif_vocab_size = len(dataset.node_type_index_to_string)\n",
    ")\n",
    "\n",
    "full_graph_encoder = GraphEncoder(**params['full_graph_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f6eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_molecule_representations = full_graph_encoder(\n",
    "    batch.original_graph_node_categorical_features, \n",
    "    batch.original_graph_x.float(),\n",
    "    batch.original_graph_edge_index,\n",
    "    batch.original_graph_edge_type,\n",
    "    batch_index = batch.original_graph_x_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be236a",
   "metadata": {},
   "source": [
    "# PartialGraphEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fc2ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import PartialGraphEncoder\n",
    "from model_utils import get_params\n",
    "params = get_params(dataset)\n",
    "# partial_graph_encoder = PartialGraphEncoder(\n",
    "#     input_feature_dim = batch.x.shape[-1],\n",
    "#     atom_or_motif_vocab_size = len(dataset.node_type_index_to_string)\n",
    "# )\n",
    "\n",
    "partial_graph_encoder = PartialGraphEncoder(**params['partial_graph_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f6bbabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_graph_encoder': {'input_feature_dim': 59,\n",
       "  'atom_or_motif_vocab_size': 166},\n",
       " 'partial_graph_encoder': {'input_feature_dim': 59,\n",
       "  'atom_or_motif_vocab_size': 166},\n",
       " 'mean_log_var_mlp': {'input_feature_dim': 832, 'output_size': 1024},\n",
       " 'decoder': {'node_type_selector': {'input_feature_dim': 1344,\n",
       "   'output_size': 167},\n",
       "  'node_type_loss_weights': tensor([10.0000,  0.1000,  3.6015,  0.1000,  0.1000,  0.4439,  0.7549,  0.4416,\n",
       "          10.0000,  2.7939,  3.3916, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,  0.1731],\n",
       "         device='cuda:0'),\n",
       "  'no_more_edges_repr': (1, 835),\n",
       "  'edge_candidate_scorer': {'input_feature_dim': 3011, 'output_size': 1},\n",
       "  'edge_type_selector': {'input_feature_dim': 3011, 'output_size': 3},\n",
       "  'attachment_point_selector': {'input_feature_dim': 2176, 'output_size': 1},\n",
       "  'first_node_type_selector': {'input_feature_dim': 512, 'output_size': 166}},\n",
       " 'latent_sample_strategy': 'per_graph',\n",
       " 'latent_repr_dim': 512,\n",
       " 'latent_repr_size': 512}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bb4770c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: 'C',\n",
       " 2: 'Br',\n",
       " 3: 'N',\n",
       " 4: 'O',\n",
       " 5: 'S',\n",
       " 6: 'Cl',\n",
       " 7: 'F',\n",
       " 8: 'P',\n",
       " 9: 'N+',\n",
       " 10: 'O-',\n",
       " 11: 'I',\n",
       " 12: 'N-',\n",
       " 13: 'S+',\n",
       " 14: 'B',\n",
       " 15: 'Si',\n",
       " 16: 'Cl+',\n",
       " 17: 'C-',\n",
       " 18: 'P+',\n",
       " 19: 'B-',\n",
       " 20: 'Se',\n",
       " 21: 'O+',\n",
       " 22: 'S-',\n",
       " 23: 'I+',\n",
       " 24: 'C+',\n",
       " 25: 'F+',\n",
       " 26: 'Se+',\n",
       " 27: 'P-',\n",
       " 28: 'I++',\n",
       " 29: 'F-',\n",
       " 30: 'Si-',\n",
       " 31: 'Cl-',\n",
       " 32: 'Se-',\n",
       " 33: 'Cl+++',\n",
       " 34: 'I+++',\n",
       " 35: 'Br-',\n",
       " 36: 'Cl++',\n",
       " 37: 'Br++',\n",
       " 38: 'C1=CC=CC=C1',\n",
       " 39: 'C1=CC=NC=C1',\n",
       " 40: 'NC=O',\n",
       " 41: 'C1CCNCC1',\n",
       " 42: 'C1CNCCN1',\n",
       " 43: 'FC(F)F',\n",
       " 44: 'C1CCNC1',\n",
       " 45: 'O=CO',\n",
       " 46: 'C1=CNN=C1',\n",
       " 47: 'O=[N+][O-]',\n",
       " 48: 'CCC',\n",
       " 49: 'C1=CN=CN=C1',\n",
       " 50: 'C1CCCCC1',\n",
       " 51: 'C1COCCN1',\n",
       " 52: 'C1=CSC=C1',\n",
       " 53: 'C1=CC=C2NC=CC2=C1',\n",
       " 54: 'CCO',\n",
       " 55: 'C1=COC=C1',\n",
       " 56: 'C1CC1',\n",
       " 57: 'O=S=O',\n",
       " 58: 'C1=CSC=N1',\n",
       " 59: 'CNC=O',\n",
       " 60: 'CC=O',\n",
       " 61: 'CC(N)=O',\n",
       " 62: 'N[SH](=O)=O',\n",
       " 63: 'C1=CNC=N1',\n",
       " 64: 'COC=O',\n",
       " 65: 'C1=CC=C2C=CC=CC2=C1',\n",
       " 66: 'CC(=O)O',\n",
       " 67: 'C1=CC=C2NC=NC2=C1',\n",
       " 68: 'C1CCOC1',\n",
       " 69: 'CCOC=O',\n",
       " 70: 'CC(C)C',\n",
       " 71: 'CNC',\n",
       " 72: 'C1CCOCC1',\n",
       " 73: 'C1CCCC1',\n",
       " 74: 'C1=CON=C1',\n",
       " 75: 'C1=CC=C2N=CC=CC2=C1',\n",
       " 76: 'C1=CNC=C1',\n",
       " 77: 'C1=CN=C2C=CC=CC2=C1',\n",
       " 78: 'CCNC=O',\n",
       " 79: 'CCCC',\n",
       " 80: 'C1=CC=C2OCOC2=C1',\n",
       " 81: 'NC(N)=O',\n",
       " 82: 'CCN',\n",
       " 83: 'C[SH](=O)=O',\n",
       " 84: 'C1=NN=CN1',\n",
       " 85: 'C1=CNCNC1',\n",
       " 86: 'C1=CNN=N1',\n",
       " 87: 'C1=CC=C2NCCC2=C1',\n",
       " 88: 'C1=CC=C2SC=NC2=C1',\n",
       " 89: 'CCCO',\n",
       " 90: 'NC(=O)CS',\n",
       " 91: 'C1=NC=NO1',\n",
       " 92: 'C1=COC=N1',\n",
       " 93: 'C1CSCN1',\n",
       " 94: 'C1=CN=CC=N1',\n",
       " 95: 'C1=NC=NN1',\n",
       " 96: 'C1CNC1',\n",
       " 97: 'C1=NN=CS1',\n",
       " 98: 'C=CC',\n",
       " 99: 'C1=NN=CO1',\n",
       " 100: 'C1=CC=C2OCC=CC2=C1',\n",
       " 101: 'C1=CC=C2CNCCC2=C1',\n",
       " 102: 'C=CC=O',\n",
       " 103: 'N=CO',\n",
       " 104: 'C1=CC=C2CNCC2=C1',\n",
       " 105: 'C1=CCNC=C1',\n",
       " 106: 'C1CNCN1',\n",
       " 107: 'C1=NN=NN1',\n",
       " 108: 'CNC(C)=O',\n",
       " 109: 'C1=CC=C2OC=CC2=C1',\n",
       " 110: 'CC(C)O',\n",
       " 111: 'C1=NC=C2N=CNC2=N1',\n",
       " 112: 'C1CCC1',\n",
       " 113: 'CCC(N)=O',\n",
       " 114: 'C1=CC=C2OC=CCC2=C1',\n",
       " 115: 'CN[SH](=O)=O',\n",
       " 116: 'OC(F)(F)F',\n",
       " 117: 'C1=CC=C2N=CNCC2=C1',\n",
       " 118: 'C1=CC=C2NN=CC2=C1',\n",
       " 119: 'C1=CC2=CN=CN=C2C=C1',\n",
       " 120: 'CCC=O',\n",
       " 121: 'C1C2CC3CC1CC(C2)C3',\n",
       " 122: 'C1=CC2=NC=CN2C=C1',\n",
       " 123: 'C1=CC=C2N=CN=CC2=C1',\n",
       " 124: 'N=CN',\n",
       " 125: 'CN(C)C=O',\n",
       " 126: 'C1=CC=C2OCCOC2=C1',\n",
       " 127: 'C1=NNCC1',\n",
       " 128: 'COC',\n",
       " 129: 'NC(=O)CO',\n",
       " 130: 'C=NNC=O',\n",
       " 131: 'CCC(=O)O',\n",
       " 132: 'C1=CC=C2CCCC2=C1',\n",
       " 133: 'C1=CN2N=CC=C2N=C1',\n",
       " 134: 'CN(C)C',\n",
       " 135: 'C1=CCCCC1',\n",
       " 136: 'COC(C)=O',\n",
       " 137: 'C1=NNN=N1',\n",
       " 138: 'C1=CC=C2SC=CC2=C1',\n",
       " 139: 'O=CCS',\n",
       " 140: 'C1CCCNCC1',\n",
       " 141: 'CCOC',\n",
       " 142: 'CS(N)(=O)=O',\n",
       " 143: 'C1=NC=NC=N1',\n",
       " 144: 'C1=CC=C2OC=NC2=C1',\n",
       " 145: 'C1=CC=[N+]C=C1',\n",
       " 146: 'C1=CC=C2NC=CCC2=C1',\n",
       " 147: 'C1COCN1',\n",
       " 148: 'C1=CC=C2OCCCC2=C1',\n",
       " 149: 'CCCNC=O',\n",
       " 150: 'C1=CC=C2CCCCC2=C1',\n",
       " 151: 'C1=CCNC1',\n",
       " 152: 'C1=NC=NC2=C1N=CN2',\n",
       " 153: 'C1=CC=C2NCCCC2=C1',\n",
       " 154: 'C1=NCCN1',\n",
       " 155: 'C1=CN=NC=C1',\n",
       " 156: 'C=CC(N)=O',\n",
       " 157: 'CCCN',\n",
       " 158: 'C1CNCCNC1',\n",
       " 159: 'C1=CC=C2N=CC=NC2=C1',\n",
       " 160: 'CCCCC',\n",
       " 161: 'C=NN',\n",
       " 162: 'CCNC(C)=O',\n",
       " 163: 'CCNC',\n",
       " 164: 'C1=CCNN=C1',\n",
       " 165: 'C1=CC=C2NCC=CC2=C1'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._node_type_index_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e5251db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MotifVocabulary(vocabulary={'C1=CC=CC=C1': 0, 'C1=CC=NC=C1': 1, 'NC=O': 2, 'C1CCNCC1': 3, 'C1CNCCN1': 4, 'FC(F)F': 5, 'C1CCNC1': 6, 'O=CO': 7, 'C1=CNN=C1': 8, 'O=[N+][O-]': 9, 'CCC': 10, 'C1=CN=CN=C1': 11, 'C1CCCCC1': 12, 'C1COCCN1': 13, 'C1=CSC=C1': 14, 'C1=CC=C2NC=CC2=C1': 15, 'CCO': 16, 'C1=COC=C1': 17, 'C1CC1': 18, 'O=S=O': 19, 'C1=CSC=N1': 20, 'CNC=O': 21, 'CC=O': 22, 'CC(N)=O': 23, 'N[SH](=O)=O': 24, 'C1=CNC=N1': 25, 'COC=O': 26, 'C1=CC=C2C=CC=CC2=C1': 27, 'CC(=O)O': 28, 'C1=CC=C2NC=NC2=C1': 29, 'C1CCOC1': 30, 'CCOC=O': 31, 'CC(C)C': 32, 'CNC': 33, 'C1CCOCC1': 34, 'C1CCCC1': 35, 'C1=CON=C1': 36, 'C1=CC=C2N=CC=CC2=C1': 37, 'C1=CNC=C1': 38, 'C1=CN=C2C=CC=CC2=C1': 39, 'CCNC=O': 40, 'CCCC': 41, 'C1=CC=C2OCOC2=C1': 42, 'NC(N)=O': 43, 'CCN': 44, 'C[SH](=O)=O': 45, 'C1=NN=CN1': 46, 'C1=CNCNC1': 47, 'C1=CNN=N1': 48, 'C1=CC=C2NCCC2=C1': 49, 'C1=CC=C2SC=NC2=C1': 50, 'CCCO': 51, 'NC(=O)CS': 52, 'C1=NC=NO1': 53, 'C1=COC=N1': 54, 'C1CSCN1': 55, 'C1=CN=CC=N1': 56, 'C1=NC=NN1': 57, 'C1CNC1': 58, 'C1=NN=CS1': 59, 'C=CC': 60, 'C1=NN=CO1': 61, 'C1=CC=C2OCC=CC2=C1': 62, 'C1=CC=C2CNCCC2=C1': 63, 'C=CC=O': 64, 'N=CO': 65, 'C1=CC=C2CNCC2=C1': 66, 'C1=CCNC=C1': 67, 'C1CNCN1': 68, 'C1=NN=NN1': 69, 'CNC(C)=O': 70, 'C1=CC=C2OC=CC2=C1': 71, 'CC(C)O': 72, 'C1=NC=C2N=CNC2=N1': 73, 'C1CCC1': 74, 'CCC(N)=O': 75, 'C1=CC=C2OC=CCC2=C1': 76, 'CN[SH](=O)=O': 77, 'OC(F)(F)F': 78, 'C1=CC=C2N=CNCC2=C1': 79, 'C1=CC=C2NN=CC2=C1': 80, 'C1=CC2=CN=CN=C2C=C1': 81, 'CCC=O': 82, 'C1C2CC3CC1CC(C2)C3': 83, 'C1=CC2=NC=CN2C=C1': 84, 'C1=CC=C2N=CN=CC2=C1': 85, 'N=CN': 86, 'CN(C)C=O': 87, 'C1=CC=C2OCCOC2=C1': 88, 'C1=NNCC1': 89, 'COC': 90, 'NC(=O)CO': 91, 'C=NNC=O': 92, 'CCC(=O)O': 93, 'C1=CC=C2CCCC2=C1': 94, 'C1=CN2N=CC=C2N=C1': 95, 'CN(C)C': 96, 'C1=CCCCC1': 97, 'COC(C)=O': 98, 'C1=NNN=N1': 99, 'C1=CC=C2SC=CC2=C1': 100, 'O=CCS': 101, 'C1CCCNCC1': 102, 'CCOC': 103, 'CS(N)(=O)=O': 104, 'C1=NC=NC=N1': 105, 'C1=CC=C2OC=NC2=C1': 106, 'C1=CC=[N+]C=C1': 107, 'C1=CC=C2NC=CCC2=C1': 108, 'C1COCN1': 109, 'C1=CC=C2OCCCC2=C1': 110, 'CCCNC=O': 111, 'C1=CC=C2CCCCC2=C1': 112, 'C1=CCNC1': 113, 'C1=NC=NC2=C1N=CN2': 114, 'C1=CC=C2NCCCC2=C1': 115, 'C1=NCCN1': 116, 'C1=CN=NC=C1': 117, 'C=CC(N)=O': 118, 'CCCN': 119, 'C1CNCCNC1': 120, 'C1=CC=C2N=CC=NC2=C1': 121, 'CCCCC': 122, 'C=NN': 123, 'CCNC(C)=O': 124, 'CCNC': 125, 'C1=CCNN=C1': 126, 'C1=CC=C2NCC=CC2=C1': 127}, settings=MotifExtractionSettings(min_frequency=None, min_num_atoms=3, cut_leaf_edges=True, max_vocab_size=128))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_type_featuriser.index_to_atom_type_map\n",
    "\n",
    "dataset.metadata.get(\"motif_vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e548999",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_graph_representions, node_representations = partial_graph_encoder(\n",
    "    partial_graph_node_categorical_features = batch.partial_node_categorical_features,\n",
    "    node_features = batch.x,\n",
    "    edge_index = batch.edge_index.long(), \n",
    "    edge_features = batch.partial_graph_edge_features.int(), \n",
    "    graph_to_focus_node_map = batch.focus_node,\n",
    "    candidate_attachment_points = batch.valid_attachment_point_choices,\n",
    "    batch_index = batch.batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93bf34e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16659, 832])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86cfa887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16659, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_categorical_features = partial_graph_encoder._embed(batch.partial_node_categorical_features)\n",
    "embedded_categorical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6782130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16659, 123])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "node_features = batch.x\n",
    "initial_node_features = torch.cat(\n",
    "    [node_features, embedded_categorical_features], axis=-1\n",
    ")\n",
    "initial_node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ae78032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_to_focus_node_map = batch.focus_node\n",
    "graph_to_focus_node_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a4e281a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  428.,   429.,   771.,   772.,   775.,   776.,   777.,   778.,   810.,\n",
       "          812.,   937.,   940.,   941.,  1061.,  1064.,  1065.,  1131.,  1134.,\n",
       "         1135.,  1836.,  1837.,  1838.,  1839.,  2279.,  2280.,  2281.,  2282.,\n",
       "         3000.,  3002.,  3007.,  3057.,  3059.,  3080.,  3082.,  3083.,  3084.,\n",
       "         3256.,  3257.,  3258.,  3259.,  3260.,  4097.,  4098.,  4101.,  4268.,\n",
       "         4270.,  4274.,  4275.,  4320.,  4321.,  4322.,  4378.,  4379.,  4380.,\n",
       "         4381.,  4382.,  4846.,  4847.,  4903.,  4904.,  4905.,  4907.,  4983.,\n",
       "         4985.,  5019.,  5020.,  5021.,  5023.,  5024.,  5025.,  5026.,  5250.,\n",
       "         5253.,  5254.,  5255.,  5256.,  5258.,  5927.,  5928.,  5930.,  6867.,\n",
       "         6870.,  7297.,  7298.,  7301.,  7323.,  7324.,  7794.,  7795.,  7796.,\n",
       "         7797.,  7798.,  7857.,  7858.,  7859.,  7861.,  7862.,  7863.,  7864.,\n",
       "         7896.,  7898.,  8271.,  8272.,  8273.,  8275.,  8276.,  8277.,  8279.,\n",
       "         8450.,  8451.,  8452.,  8453.,  8454.,  8724.,  8725.,  8726.,  8727.,\n",
       "         8729.,  9144.,  9145.,  9614.,  9615.,  9616.,  9617.,  9668.,  9669.,\n",
       "         9670.,  9671., 11008., 11009., 11010., 11011., 11013., 11832., 11833.,\n",
       "        11834., 11835., 11837., 11838., 11839., 11976., 11978., 11979., 11980.,\n",
       "        11981., 12096., 12097., 12098., 12162., 12164., 12165., 12166., 12167.,\n",
       "        12692., 12693., 13971., 13974., 14210., 14213., 14214., 14556., 14557.,\n",
       "        14560., 15492., 15494., 15675., 15677., 15682., 15683., 15807., 15810.,\n",
       "        16533., 16536., 16537., 16538., 16539., 16541.], dtype=torch.float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_attachment_points = batch.valid_attachment_point_choices\n",
    "candidate_attachment_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77d00bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6000e+01, 1.7000e+01, 1.9000e+01,  ..., 1.6538e+04, 1.6539e+04,\n",
       "        1.6541e+04], dtype=torch.float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_to_set_in_focus_bit = torch.cat(\n",
    "    [graph_to_focus_node_map, candidate_attachment_points], axis=0\n",
    ")\n",
    "nodes_to_set_in_focus_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "258cab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   16,    17,    19,  ..., 16538, 16539, 16541], dtype=torch.int32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_to_set_in_focus_bit.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eddc8dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(node_is_in_focus_bit[nodes_to_set_in_focus_bit.long()]>=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3031b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_is_in_focus_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fc60472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(nodes_to_set_in_focus_bit.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5e0cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16659, 1])\n"
     ]
    }
   ],
   "source": [
    "node_is_in_focus_bit_zeros = torch.zeros(node_features.shape[0], 1)\n",
    "print(node_is_in_focus_bit_zeros.shape)\n",
    "node_is_in_focus_bit = node_is_in_focus_bit_zeros.index_add_(\n",
    "    dim = 0, \n",
    "    index = nodes_to_set_in_focus_bit.int(), \n",
    "    source = torch.ones(nodes_to_set_in_focus_bit.shape[0], 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6080211",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_is_in_focus_bit = torch.minimum(node_is_in_focus_bit, torch.ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f613c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_node_features = torch.cat([initial_node_features, node_is_in_focus_bit], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_graph_representions, node_representations = partial_graph_encoder(initial_node_features, batch.edge_index.long(), batch.edge_type, batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37317282",
   "metadata": {},
   "source": [
    "# _mean_log_var_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericMLP\n",
    "latent_dim = 512\n",
    "params['mean_log_var_mlp'] = {\n",
    "    'input_feature_dim': input_molecule_representations.shape[-1],\n",
    "    'output_size': latent_dim * 2\n",
    "}\n",
    "\n",
    "\n",
    "mean_log_var_mlp = GenericMLP(**params['mean_log_var_mlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1396e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_and_log_var = mean_log_var_mlp(input_molecule_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = mean_and_log_var[:, : latent_dim]  # Shape: [V, MD]\n",
    "log_var = mean_and_log_var[:, latent_dim :]  # Shape: [V, MD]\n",
    "\n",
    "# result_representations: shape [num_partial_graphs, latent_repr_dim]\n",
    "std = torch.exp(log_var / 2)\n",
    "p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "q = torch.distributions.Normal(mu, std)\n",
    "z = q.rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c5e05",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder import MLPDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b171e",
   "metadata": {},
   "source": [
    "## PickAtomOrMotif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c283c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molecule_generation.utils.training_utils import get_class_balancing_weights\n",
    "\n",
    "\n",
    "next_node_type_distribution = dataset.metadata.get(\"train_next_node_type_distribution\")\n",
    "class_weight_factor = params.get(\"node_type_predictor_class_loss_weight_factor\", 1.0)\n",
    "\n",
    "if not (0.0 <= class_weight_factor <= 1.0):\n",
    "    raise ValueError(\n",
    "        f\"Node class loss weight node_classifier_class_loss_weight_factor must be in [0,1], but is {class_weight_factor}!\"\n",
    "    )\n",
    "if class_weight_factor > 0:\n",
    "    atom_type_nums = [\n",
    "        next_node_type_distribution[dataset.node_type_index_to_string[type_idx]]\n",
    "        for type_idx in range(dataset.num_node_types)\n",
    "    ]\n",
    "    atom_type_nums.append(next_node_type_distribution[\"None\"])\n",
    "\n",
    "    class_weights = get_class_balancing_weights(\n",
    "        class_counts=atom_type_nums, class_weight_factor=class_weight_factor\n",
    "    )\n",
    "else:\n",
    "    class_weights = None\n",
    "    \n",
    "    \n",
    "    \n",
    "params['node_type_loss_weights'] = torch.tensor(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericMLP\n",
    "params['node_type_selector'] = {\n",
    "    'input_feature_dim':  z.shape[-1] + partial_graph_representions.shape[-1], \n",
    "    'output_size': dataset.num_node_types + 1\n",
    "}\n",
    "\n",
    "\n",
    "graphs_requiring_node_choices = batch.correct_node_type_choices_batch.unique()\n",
    "\n",
    "node_type_selector = GenericMLP(\n",
    "    input_feature_dim = z.shape[-1] + partial_graph_representions.shape[-1],\n",
    "    output_size = dataset.num_node_types,\n",
    ")\n",
    "\n",
    "node_type_selector = GenericMLP(**params['node_type_selector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8408b",
   "metadata": {},
   "source": [
    "### node loss computation in the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = MLPDecoder(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_logits = decoder.pick_node_type(\n",
    "    z,\n",
    "    partial_graph_representions,\n",
    "    graphs_requiring_node_choices = batch.correct_node_type_choices_batch.unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb22978",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_node_type_choices = batch.correct_node_type_choices_ptr.unique().shape[-1] -1\n",
    "node_type_multihot_labels = batch.correct_node_type_choices.view(num_correct_node_type_choices, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a721fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_type_multihot_labels = []\n",
    "# for i in range(len(batch.correct_node_type_choices_ptr)-1):\n",
    "#     start_idx = batch.correct_node_type_choices_ptr[i]\n",
    "#     end_idx = batch.correct_node_type_choices_ptr[i+1] \n",
    "#     if end_idx - start_idx == 0:\n",
    "#         continue\n",
    "#     node_selection_labels = batch.correct_node_type_choices[start_idx: end_idx]\n",
    "#     node_type_multihot_labels += [node_selection_labels]\n",
    "    \n",
    "# node_type_multihot_labels = torch.stack(node_type_multihot_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70656923",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_selection_loss = decoder.compute_node_type_selection_loss(\n",
    "    node_logits,\n",
    "    node_type_multihot_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03812ff3",
   "metadata": {},
   "source": [
    "# PickEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad35cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params['no_more_edges_repr'] = (1,node_representations.shape[-1] + batch.edge_features.shape[-1])\n",
    "params['edge_candidate_scorer'] = {\n",
    "    'input_feature_dim': 3011,\n",
    "    'output_size': 1\n",
    "}\n",
    "\n",
    "params['edge_type_selector'] = {\n",
    "    'input_feature_dim': 3011,\n",
    "    'output_size': 3\n",
    "}\n",
    "\n",
    "\n",
    "_no_more_edges_representation = torch.nn.Parameter(torch.FloatTensor(*params['no_more_edges_repr']), requires_grad = True)\n",
    "_edge_candidate_scorer = GenericMLP(**params['edge_candidate_scorer'])\n",
    "_edge_type_selector = GenericMLP(**params['edge_type_selector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c975341",
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.nn.Parameter(torch.rand(*params['no_more_edges_repr']), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e32e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from decoder import MLPDecoder\n",
    "decoder = MLPDecoder(params)\n",
    "edge_candidate_logits, edge_type_logits = decoder.pick_edge(\n",
    "    z,\n",
    "    partial_graph_representions,\n",
    "    node_representations,\n",
    "    num_graphs_in_batch = len(batch.ptr) - 1,\n",
    "    graph_to_focus_node_map= batch.focus_node,\n",
    "    node_to_graph_map=batch.batch,\n",
    "    candidate_edge_targets= batch.valid_edge_choices[:, 1].long(),\n",
    "    candidate_edge_features= batch.edge_features\n",
    ")\n",
    "decoder.compute_edge_candidate_selection_loss(\n",
    "    num_graphs_in_batch= len(batch.ptr)-1,\n",
    "    node_to_graph_map=batch.batch,\n",
    "    candidate_edge_targets= batch.valid_edge_choices[:, 1].long(),\n",
    "    edge_candidate_logits = edge_candidate_logits, # as is\n",
    "    per_graph_num_correct_edge_choices= batch.num_correct_edge_choices,\n",
    "    edge_candidate_correctness_labels = batch.correct_edge_choices,\n",
    "    no_edge_selected_labels = batch.stop_node_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8bc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.compute_edge_type_selection_loss(\n",
    "    batch.valid_edge_types,  # batch.valid_edge_types\n",
    "    edge_type_logits,\n",
    "    batch.correct_edge_choices,  # batch.correct_edge_choices\n",
    "    edge_type_onehot_labels = batch.correct_edge_types,  # batch.correct_edge_types\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ff670",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.compute_edge_type_selection_loss(\n",
    "    num_graphs_in_batch= len(batch.ptr)-1,\n",
    "    node_to_graph_map=batch.batch,\n",
    "    candidate_edge_targets= batch.valid_edge_choices[:, 1].long(),\n",
    "    edge_candidate_logits = edge_candidate_logits, # as is\n",
    "    per_graph_num_correct_edge_choices= batch.num_correct_edge_choices,\n",
    "    edge_candidate_correctness_labels = batch.correct_edge_choices,\n",
    "    no_edge_selected_labels = batch.stop_node_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad328a1",
   "metadata": {},
   "source": [
    "## pick attachement point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for batch2 in loader:\n",
    "    if len(batch2.correct_attachment_point_choice) > 0 :\n",
    "        tmp.append(batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 1\n",
    "\n",
    "tmp[sample_idx].correct_attachment_point_choice, tmp[sample_idx].valid_attachment_point_choices, tmp[sample_idx].valid_attachment_point_choices_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7097217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2 = tmp[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c591326",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['attachment_point_selector'] = {\n",
    "    'input_feature_dim': 2176,\n",
    "    'output_size': 1\n",
    "}\n",
    "_attachment_point_selector = GenericMLP(**params['attachment_point_selector'])\n",
    "def pick_attachment_point(\n",
    "    input_molecule_representations, # as is\n",
    "    partial_graph_representions, # partial_graph_representions\n",
    "    node_representations, #as is\n",
    "    node_to_graph_map, # batch.batch\n",
    "    candidate_attachment_points, # valid_attachment_point_choices\n",
    "):\n",
    "    original_and_calculated_graph_representations = torch.cat(\n",
    "        [input_molecule_representations, partial_graph_representions],\n",
    "        axis=-1,\n",
    "    )  # Shape: [PG, MD + PD]\n",
    "    \n",
    "    # Map attachment point candidates to their respective partial graphs.\n",
    "    partial_graphs_for_attachment_point_choices = node_to_graph_map[candidate_attachment_points] # Shape: [CA]\n",
    "    \n",
    "    # To score an attachment point, we condition on the representations of input and partial\n",
    "    # graphs, along with the representation of the attachment point candidate in question.\n",
    "    attachment_point_representations = torch.cat(\n",
    "        [\n",
    "            original_and_calculated_graph_representations[partial_graphs_for_attachment_point_choices],\n",
    "            node_representations[candidate_attachment_points],\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )  # Shape: [CA, MD + PD + VD*(num_layers+1)]\n",
    "    print(attachment_point_representations.shape)\n",
    "    attachment_point_selection_logits = torch.squeeze(_attachment_point_selector(attachment_point_representations), axis = -1)\n",
    "\n",
    "    \n",
    "    return attachment_point_selection_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_molecule_representations = full_graph_encoder(\n",
    "    batch2.original_graph_node_categorical_features, \n",
    "    batch2.original_graph_x.float(),\n",
    "    batch2.original_graph_edge_index,\n",
    "    batch2.original_graph_edge_type,\n",
    "    batch_index = batch2.original_graph_x_batch,\n",
    ")\n",
    "\n",
    "\n",
    "partial_graph_representions, node_representations = partial_graph_encoder(batch2.x, batch2.edge_index.long(), batch2.edge_type.int(), batch2.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbde0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2.valid_attachment_point_choices_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attachment_point_selection_logits = pick_attachment_point(\n",
    "    z, # as is\n",
    "    partial_graph_representions, # partial_graph_representions\n",
    "    node_representations, #as is\n",
    "    node_to_graph_map= batch2.batch,\n",
    "    candidate_attachment_points = batch2.valid_attachment_point_choices.long()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attachment_point_selection_loss(\n",
    "    attachment_point_selection_logits, # as is\n",
    "    attachment_point_candidate_to_graph_map,# = batch2.valid_attachment_point_choices_batch.long(),\n",
    "    attachment_point_correct_choices,# = batch2.correct_attachment_point_choices\n",
    "):\n",
    "    # Compute log softmax of the logits within each partial graph.\n",
    "    attachment_point_candidate_logprobs = (\n",
    "        traced_unsorted_segment_log_softmax(\n",
    "            logits=attachment_point_selection_logits,\n",
    "            segment_ids=attachment_point_candidate_to_graph_map,\n",
    "        )\n",
    "        * 1.0\n",
    "    )  # Shape: [CA]\n",
    "    \n",
    "    attachment_point_correct_choice_neglogprobs = -attachment_point_candidate_logprobs[attachment_point_correct_choices]\n",
    "     # Shape: [AP]\n",
    "    \n",
    "    attachment_point_selection_loss = safe_divide_loss(\n",
    "        (attachment_point_correct_choice_neglogprobs).sum(),\n",
    "        attachment_point_correct_choice_neglogprobs.shape[0],\n",
    "    )\n",
    "    return attachment_point_selection_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_attachment_point_selection_loss(\n",
    "#     attachment_point_selection_logits =  attachment_point_selection_logits,\n",
    "#     attachment_point_candidate_to_graph_map = batch2.valid_attachment_point_choices_batch.long(),\n",
    "#     attachment_point_correct_choices = batch2.correct_attachment_point_choice.long()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7873b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baa317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder import MLPDecoder\n",
    "\n",
    "\n",
    "decoder = MLPDecoder(params)\n",
    "attachment_point_selection_logits = decoder.pick_attachment_point(\n",
    "    z, # as is\n",
    "    partial_graph_representions, # partial_graph_representions\n",
    "    node_representations, #as is\n",
    "    node_to_graph_map= batch2.batch,\n",
    "    candidate_attachment_points = batch2.valid_attachment_point_choices.long()\n",
    ")\n",
    "decoder.compute_attachment_point_selection_loss(\n",
    "    attachment_point_selection_logits =  attachment_point_selection_logits,\n",
    "    attachment_point_candidate_to_graph_map = batch2.valid_attachment_point_choices_batch.long(),\n",
    "    attachment_point_correct_choices = batch2.correct_attachment_point_choice.long()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63706fcd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "node_logits,edge_candidate_logits,edge_type_logits,attachment_point_selection_logits = decoder(\n",
    "    input_molecule_representations = z,\n",
    "    graph_representations = partial_graph_representions,\n",
    "    graphs_requiring_node_choices = batch.correct_node_type_choices_batch.unique(),\n",
    "    # edge selection\n",
    "    node_representations = node_representations,\n",
    "    num_graphs_in_batch = len(batch.ptr) -1,\n",
    "    graph_to_focus_node_map =batch.focus_node,\n",
    "    node_to_graph_map = batch.batch,\n",
    "    candidate_edge_targets = batch.valid_edge_choices[:, 1].long(),\n",
    "    candidate_edge_features = batch.edge_features,\n",
    "    # attachment selection\n",
    "    candidate_attachment_points = batch.valid_attachment_point_choices.long(),\n",
    ")\n",
    "\n",
    "\n",
    "loss = decoder.compute_decoder_loss(\n",
    "    node_type_logits = node_logits,\n",
    "    node_type_multihot_labels = node_type_multihot_labels,\n",
    "    num_graphs_in_batch= len(batch.ptr)-1,\n",
    "    node_to_graph_map=batch.batch,\n",
    "    candidate_edge_targets= batch.valid_edge_choices[:, 1].long(),\n",
    "    edge_candidate_logits = edge_candidate_logits, # as is\n",
    "    per_graph_num_correct_edge_choices= batch.num_correct_edge_choices,\n",
    "    edge_candidate_correctness_labels = batch.correct_edge_choices,\n",
    "    no_edge_selected_labels = batch.stop_node_label,\n",
    "    attachment_point_selection_logits =  attachment_point_selection_logits,\n",
    "    attachment_point_candidate_to_graph_map = batch.valid_attachment_point_choices_batch.long(),\n",
    "    attachment_point_correct_choices = batch.correct_attachment_point_choice.long()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8beb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2762a7",
   "metadata": {},
   "source": [
    "# pick first node type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23498a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.correct_first_node_type_choices_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericMLP\n",
    "params['first_node_type_selector'] = {\n",
    "    'input_feature_dim':  partial_graph_representions.shape[-1], \n",
    "    'output_size': dataset.num_node_types # cant have no node as the starting point so no need to + 1\n",
    "}\n",
    "\n",
    "first_node_type_selector = GenericMLP(**params['first_node_type_selector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea860568",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95742011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_first_node_type(\n",
    "    partial_graph_representions\n",
    "):\n",
    "    return first_node_type_selector(partial_graph_representions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_node_type_logits = pick_first_node_type(partial_graph_representions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a52c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first_node_type_selection_loss(\n",
    "    first_node_type_logits,\n",
    "    first_node_type_multihot_labels,\n",
    "):\n",
    "    per_graph_logprobs = torch.nn.functional.log_softmax(first_node_type_logits, dim = -1)\n",
    "    per_graph_num_correct_choices = torch.sum(first_node_type_multihot_labels, axis = -1, keepdims = True)\n",
    "    per_graph_normalised_neglogprob = compute_neglogprob_for_multihot_objective(\n",
    "        logprobs=per_graph_logprobs,\n",
    "        multihot_labels=first_node_type_multihot_labels,\n",
    "        per_decision_num_correct_choices=per_graph_num_correct_choices,\n",
    "    ) \n",
    "#     if self._first_node_type_loss_weights is not None:\n",
    "#         per_graph_normalised_neglogprob *= self._node_type_loss_weights[:-1]\n",
    "        \n",
    "    first_node_type_loss = safe_divide_loss(\n",
    "        torch.sum(per_graph_normalised_neglogprob),\n",
    "        first_node_type_multihot_labels.shape[0],\n",
    "    )\n",
    "    return first_node_type_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239dee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_node_type_multihot_labels = batch.correct_first_node_type_choices.view(len(batch.ptr) -1, -1)\n",
    "\n",
    "compute_first_node_type_selection_loss(\n",
    "    first_node_type_logits,\n",
    "    first_node_type_multihot_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a74ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c105faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['decoder'] = {\n",
    "    'node_type_selector': params[\"node_type_selector\"],\n",
    "    'node_type_loss_weights': params[\"node_type_loss_weights\"],\n",
    "    'no_more_edges_repr':params[\"no_more_edges_repr\"],\n",
    "    'edge_candidate_scorer':params[\"edge_candidate_scorer\"],\n",
    "    'edge_type_selector':params[\"edge_type_selector\"], \n",
    "    'attachment_point_selector':params[\"attachment_point_selector\"],\n",
    "}\n",
    "\n",
    "params['latent_sample_strategy'] = 'per_graph'\n",
    "params['latent_repr_size'] = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2178d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86001db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import BaseModel\n",
    "\n",
    "params= get_params()\n",
    "model = BaseModel(params, dataset)\n",
    "\n",
    "moler_output = model._run_step(batch)\n",
    "\n",
    "loss = model.compute_loss(moler_output, batch)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384df024",
   "metadata": {},
   "outputs": [],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9dbf8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from torch_geometric.data.lightning_datamodule import LightningDataset\n",
    "# datamodule = LightningDataset(dataset)\n",
    "trainer = Trainer(overfit_batches=1)\n",
    "trainer.fit(model, loader, loader)\n",
    "# trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce597ec",
   "metadata": {},
   "source": [
    "# LightningModule + Vae MLP\n",
    "\n",
    "1. Implement kd divergence loss as part of the lightning module\n",
    "2. Investigate where node_type_predictor_class_loss_weight_factor is supposed to come from, otherwise, default to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8364308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a0103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257f1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
