{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5caa28ca",
   "metadata": {},
   "source": [
    "# Design \n",
    "\n",
    "1. All model related loss computations and helper functions are in torch.modules and they will all be called compute_loss \n",
    "2. The MLPDecoder will house all the MLPs involved in the decoder and will have 1 compute_decoder_loss_method that will call all the individual compute_loss methods.\n",
    "\n",
    "It will also have a decode method that will do decoding at inference time(TODO)\n",
    "\n",
    "3. The FullGraphEncoder and the PartialGraphEncoder will each be in their own torch modules\n",
    "\n",
    "4. Finally, the lightning module will have 3 things: \n",
    "- FullGraphEncoder\n",
    "- PartialGraphEncoder (part of decoder)\n",
    "- MLPDecoder\n",
    "\n",
    "And after passing through the initial FullGraphEncoder, if we are working with a VAE, we will extract p and q for computing the kl divergence loss, otherwise we will do the other model specific stuff like diffusion.\n",
    "\n",
    "`params` dictionary will be passed to the lightning module and each torch module will be constructed within it using the relevant parameters by destructuring the dictionary \n",
    "\n",
    "node type class weights will be instantiated in the lightning module and passed to the decoder\n",
    "\n",
    "# TODO\n",
    "1. fix the incrementing in the original graph edge index (DONE)\n",
    "2. Work on first node prediction \n",
    "3. Investigate node_type_predictor_class_loss_weight_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c82689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params houses all relevant model instantiation parameters\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "75459146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import MolerDataset, MolerData\n",
    "from utils import pprint_pyg_obj\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50a5acbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = MolerDataset(\n",
    "    root = '/data/ongh0068', \n",
    "    raw_moler_trace_dataset_parent_folder = '/data/ongh0068/l1000/trace_playground',\n",
    "    output_pyg_trace_dataset_parent_folder = '/data/ongh0068/l1000/pyg_output_playground',\n",
    "    split = 'train',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b80108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=16, shuffle=False, follow_batch = [\n",
    "    'correct_edge_choices',\n",
    "    'correct_edge_types',\n",
    "    'valid_edge_choices',\n",
    "    'valid_attachment_point_choices',\n",
    "    'correct_attachment_point_choice',\n",
    "    'correct_node_type_choices',\n",
    "    'original_graph_x'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "340217e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea61240",
   "metadata": {},
   "source": [
    "# FullGraphEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "728b29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericGraphEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59373d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(torch.nn.Module):\n",
    "    \"\"\"Returns graph level representation of the molecules.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_feature_dim,\n",
    "        atom_or_motif_vocab_size,\n",
    "        motif_embedding_size = 64,\n",
    "        hidden_layer_feature_dim=64,\n",
    "        num_layers=12,\n",
    "        layer_type=\"RGATConv\",\n",
    "        use_intermediate_gnn_results=True,\n",
    "    ):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self._embed = torch.nn.Embedding(atom_or_motif_vocab_size, motif_embedding_size)\n",
    "        self._model = GenericGraphEncoder(input_feature_dim = motif_embedding_size + input_feature_dim)\n",
    "        \n",
    "    def forward(self, original_graph_node_categorical_features, node_features, edge_index, edge_type, batch_index):\n",
    "        motif_embeddings = self._embed(original_graph_node_categorical_features)\n",
    "        node_features = torch.cat((node_features, motif_embeddings), axis = -1)\n",
    "        input_molecule_representations, _ = self._model(node_features, edge_index.long(), edge_type, batch_index)\n",
    "        return input_molecule_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c1ca9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['full_graph_encoder'] = {\n",
    "    'input_feature_dim': batch.x.shape[-1],\n",
    "    'atom_or_motif_vocab_size': len(dataset.node_type_index_to_string)\n",
    "}\n",
    "\n",
    "full_graph_encoder = GraphEncoder(\n",
    "    input_feature_dim = batch.x.shape[-1],\n",
    "    atom_or_motif_vocab_size = len(dataset.node_type_index_to_string)\n",
    ")\n",
    "\n",
    "full_graph_encoder = GraphEncoder(**params['full_graph_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "23f6eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_molecule_representations = full_graph_encoder(\n",
    "    batch.original_graph_node_categorical_features, \n",
    "    batch.original_graph_x.float(),\n",
    "    batch.original_graph_edge_index,\n",
    "    batch.original_graph_edge_type,\n",
    "    batch_index = batch.original_graph_x_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be236a",
   "metadata": {},
   "source": [
    "# PartialGraphEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4fc2ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['partial_graph_encoder'] = {\n",
    "    'input_feature_dim': batch.x.shape[-1],\n",
    "}\n",
    "\n",
    "partial_graph_encoder = GenericGraphEncoder(\n",
    "    input_feature_dim = batch.x.shape[-1],\n",
    ")\n",
    "\n",
    "partial_graph_encoder = GenericGraphEncoder(**params['partial_graph_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f86d6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_graph_representions, node_representations = partial_graph_encoder(batch.x, batch.edge_index.long(), batch.edge_type, batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1bb0cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([193, 832])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37317282",
   "metadata": {},
   "source": [
    "# _mean_log_var_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c80a78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericMLP\n",
    "latent_dim = 512\n",
    "params['mean_log_var_mlp'] = {\n",
    "    'input_feature_dim': input_molecule_representations.shape[-1],\n",
    "    'output_size': latent_dim * 2\n",
    "}\n",
    "\n",
    "\n",
    "mean_log_var_mlp = GenericMLP(**params['mean_log_var_mlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c1396e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_and_log_var = mean_log_var_mlp(input_molecule_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eec0a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = mean_and_log_var[:, : latent_dim]  # Shape: [V, MD]\n",
    "log_var = mean_and_log_var[:, latent_dim :]  # Shape: [V, MD]\n",
    "\n",
    "# result_representations: shape [num_partial_graphs, latent_repr_dim]\n",
    "std = torch.exp(log_var / 2)\n",
    "p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "q = torch.distributions.Normal(mu, std)\n",
    "z = q.rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "149bc619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c5e05",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "de6b929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import safe_divide_loss, compute_neglogprob_for_multihot_objective\n",
    "from model_utils import GenericMLP\n",
    "\n",
    "\n",
    "class MLPDecoder(torch.nn.Module):\n",
    "    \"\"\"Returns graph level representation of the molecules.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        params, # nested dictionary of parameters for each MLP\n",
    "    ):\n",
    "        super(MLPDecoder, self).__init__()\n",
    "        # Node selection \n",
    "        self._node_type_selector = GenericMLP(**params['node_type_selector'])\n",
    "        self._node_type_loss_weights = params['node_type_loss_weights']\n",
    "        \n",
    "        # Edge selection\n",
    "        self._no_more_edges_representation = torch.nn.Parameter(torch.FloatTensor(*params['no_more_edges_repr']), requires_grad = True)\n",
    "        self._edge_candidate_scorer = GenericMLP(**params['edge_candidate_scorer'])\n",
    "        self._edge_type_selector = GenericMLP(**params['edge_type_selector'])\n",
    "        \n",
    "        \n",
    "        # Attachment Point Selection\n",
    "        \n",
    "        \n",
    "    def pick_node_type(\n",
    "        self,\n",
    "        input_molecule_representations,\n",
    "        graph_representations,\n",
    "        graphs_requiring_node_choices\n",
    "    ):\n",
    "        relevant_graph_representations = input_molecule_representations[graphs_requiring_node_choices]\n",
    "        relevant_input_molecule_representations = graph_representations[graphs_requiring_node_choices]\n",
    "        original_and_calculated_graph_representations = torch.cat((relevant_graph_representations,relevant_input_molecule_representations), axis = -1)\n",
    "        node_type_logits = self._node_type_selector(original_and_calculated_graph_representations)\n",
    "        return node_type_logits\n",
    "    \n",
    "    def compute_node_type_selection_loss(\n",
    "        self,\n",
    "        node_type_logits,\n",
    "        node_type_multihot_labels\n",
    "    ):\n",
    "        per_node_decision_logprobs = torch.nn.functional.log_softmax(node_type_logits, dim = -1)\n",
    "        # Shape: [NTP, NT + 1]\n",
    "\n",
    "        # number of correct choices for each of the partial graphs that require node choices\n",
    "        per_node_decision_num_correct_choices = torch.sum(node_type_multihot_labels, keepdim = True, axis = -1)\n",
    "        # Shape [NTP, 1]\n",
    "\n",
    "        per_correct_node_decision_normalised_neglogprob = compute_neglogprob_for_multihot_objective(\n",
    "            logprobs = per_node_decision_logprobs[:, :-1], # separate out the no node prediction\n",
    "            multihot_labels = node_type_multihot_labels,\n",
    "            per_decision_num_correct_choices = per_node_decision_num_correct_choices,\n",
    "        ) # Shape [NTP, NT]\n",
    "\n",
    "        no_node_decision_correct =(per_node_decision_num_correct_choices == 0.0).sum()  # Shape [NTP]\n",
    "        per_correct_no_node_decision_neglogprob = -(\n",
    "            per_node_decision_logprobs[:, -1]\n",
    "            * torch.squeeze(no_node_decision_correct).type(torch.FloatTensor)\n",
    "        )  # Shape [NTP]\n",
    "\n",
    "        if self._node_type_loss_weights is not None:\n",
    "            per_correct_node_decision_normalised_neglogprob *= self._node_type_loss_weights[:-1]\n",
    "            per_correct_no_node_decision_neglogprob *= self._node_type_loss_weights[-1]\n",
    "\n",
    "        # Loss is the sum of the masked (no) node decisions, averaged over number of decisions made:\n",
    "        total_node_type_loss = torch.sum(\n",
    "            per_correct_node_decision_normalised_neglogprob\n",
    "        ) + torch.sum(per_correct_no_node_decision_neglogprob)\n",
    "        node_type_loss = safe_divide_loss(\n",
    "            total_node_type_loss, node_type_multihot_labels.shape[0]\n",
    "        )\n",
    "\n",
    "        return node_type_loss\n",
    "\n",
    "    \n",
    "    def compute_edge_candidate_selection_loss(\n",
    "        num_graphs_in_batch, # correct_node_type_choices\n",
    "        node_to_graph_map, #batch.batch\n",
    "        candidate_edge_targets, # batch_features[\"valid_edge_choices\"][:, 1]\n",
    "        edge_candidate_logits, # as is\n",
    "        per_graph_num_correct_edge_choices, # batch.num_correct_edge_choices\n",
    "        edge_candidate_correctness_labels, # correct edge choices\n",
    "        no_edge_selected_labels # stop node label\n",
    "    ):\n",
    "\n",
    "        # First, we construct full labels for all edge decisions, which are the concat of\n",
    "        # edge candidate logits and the logits for choosing no edge:\n",
    "        edge_correctness_labels = torch.cat(\n",
    "            [edge_candidate_correctness_labels, no_edge_selected_labels.float()],\n",
    "            axis=0,\n",
    "        )  # Shape: [CE + PG]\n",
    "\n",
    "        # To compute a softmax over all candidate edges (and the \"no edge\" choice) corresponding\n",
    "        # to the same graph, we first need to build the map from each logit to the corresponding\n",
    "        # graph id. Then, we can do an unsorted_segment_softmax using that map:\n",
    "        edge_candidate_to_graph_map = batch.batch[candidate_edge_target_node_idx]\n",
    "        # add the end bond labels to the end \n",
    "        edge_candidate_to_graph_map = torch.cat((edge_candidate_to_graph_map, torch.arange(0, num_graphs_in_batch)))\n",
    "\n",
    "        edge_candidate_logprobs = traced_unsorted_segment_log_softmax(\n",
    "            logits=edge_candidate_logits,\n",
    "            segment_ids=edge_candidate_to_graph_map,\n",
    "            num_segments=num_graphs_in_batch,\n",
    "        )  # Shape: [CE + PG]\n",
    "\n",
    "        # Compute the edge loss with the multihot objective.\n",
    "        # For a single graph with three valid choices (+ stop node) of which two are correct,\n",
    "        # we may have the following:\n",
    "        #  edge_candidate_logprobs = log([0.05, 0.5, 0.4, 0.05])\n",
    "        #  per_graph_num_correct_edge_choices = [2]\n",
    "        #  edge_candidate_correctness_labels = [0.0, 1.0, 1.0]\n",
    "        #  edge_correctness_labels = [0.0, 1.0, 1.0, 0.0]\n",
    "        # To get the loss, we simply look at the things in edge_candidate_logprobs that correspond\n",
    "        # to correct entries.\n",
    "        # However, to account for the _multi_hot nature, we scale up each entry of\n",
    "        # edge_candidate_logprobs by the number of correct choices, i.e., consider the\n",
    "        # correct entries of\n",
    "        #  log([0.05, 0.5, 0.4, 0.05]) + log([2, 2, 2, 2]) = log([0.1, 1.0, 0.8, 0.1])\n",
    "        # In this form, we want to have each correct entry to be as near possible to 1.\n",
    "        # Finally, we normalise loss contributions to by-graph, by dividing the crossentropy\n",
    "        # loss by the number of correct choices (i.e., in the example above, this results in\n",
    "        # a loss of -((log(1.0) + log(0.8)) / 2) = 0.11...).\n",
    "\n",
    "        # Note: per_graph_num_correct_edge_choices does not include the choice of an edge to\n",
    "        # the stop node, so can be zero.\n",
    "        per_graph_num_correct_edge_choices = torch.max(\n",
    "            per_graph_num_correct_edge_choices, torch.ones(per_graph_num_correct_edge_choices.shape)\n",
    "        )  # Shape: [PG]\n",
    "\n",
    "\n",
    "        per_edge_candidate_num_correct_choices = per_graph_num_correct_edge_choices[edge_candidate_to_graph_map]\n",
    "        # Shape: [CE]\n",
    "        per_correct_edge_neglogprob = -(\n",
    "            (edge_candidate_logprobs + torch.log(per_edge_candidate_num_correct_choices))\n",
    "            * edge_correctness_labels\n",
    "            / per_edge_candidate_num_correct_choices\n",
    "        )  # Shape: [CE]\n",
    "\n",
    "        # Normalise by number of graphs for which we made edge selection decisions:\n",
    "        edge_loss = safe_divide_loss(\n",
    "            torch.sum(per_correct_edge_neglogprob), num_graphs_in_batch\n",
    "        )\n",
    "\n",
    "        return edge_loss    \n",
    "    \n",
    "    def compute_decoder_loss(\n",
    "        node_type_logits,\n",
    "        node_type_multihot_labels\n",
    "    \n",
    "    ):\n",
    "        # Compute node selection loss\n",
    "        node_selection_loss = self.compute_node_type_selection_loss(\n",
    "            node_type_logits,\n",
    "            node_type_multihot_labels\n",
    "        )\n",
    "        \n",
    "        # Compute edge selection loss \n",
    "        \n",
    "        \n",
    "        # Compute attachement point selection loss\n",
    "        \n",
    "        \n",
    "        # Weighted sum of the losses and return it for backpropagation in\n",
    "        # the lightning module\n",
    "        return node_selection_loss\n",
    "        \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_molecule_representations,\n",
    "        graph_representations,\n",
    "        graphs_requiring_node_choices\n",
    "    \n",
    "    ):\n",
    "        # Compute node logits\n",
    "        node_logits = self.pick_node_type(\n",
    "            input_molecule_representations,\n",
    "            graph_representations,\n",
    "            graphs_requiring_node_choices\n",
    "        )\n",
    "        \n",
    "        # Compute edge logits\n",
    "        \n",
    "        \n",
    "        # Compute attachment point logits\n",
    "        \n",
    "        \n",
    "        \n",
    "        # return all logits\n",
    "        return node_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b171e",
   "metadata": {},
   "source": [
    "## PickAtomOrMotif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2c283c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molecule_generation.utils.training_utils import get_class_balancing_weights\n",
    "\n",
    "\n",
    "next_node_type_distribution = dataset.metadata.get(\"train_next_node_type_distribution\")\n",
    "class_weight_factor = params.get(\"node_type_predictor_class_loss_weight_factor\", 1.0)\n",
    "\n",
    "if not (0.0 <= class_weight_factor <= 1.0):\n",
    "    raise ValueError(\n",
    "        f\"Node class loss weight node_classifier_class_loss_weight_factor must be in [0,1], but is {class_weight_factor}!\"\n",
    "    )\n",
    "if class_weight_factor > 0:\n",
    "    atom_type_nums = [\n",
    "        next_node_type_distribution[dataset.node_type_index_to_string[type_idx]]\n",
    "        for type_idx in range(dataset.num_node_types)\n",
    "    ]\n",
    "    atom_type_nums.append(next_node_type_distribution[\"None\"])\n",
    "\n",
    "    class_weights = get_class_balancing_weights(\n",
    "        class_counts=atom_type_nums, class_weight_factor=class_weight_factor\n",
    "    )\n",
    "else:\n",
    "    class_weights = None\n",
    "    \n",
    "    \n",
    "    \n",
    "params['node_type_loss_weights'] = torch.tensor(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "11ae57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericMLP\n",
    "params['node_type_selector'] = {\n",
    "    'input_feature_dim':  z.shape[-1] + partial_graph_representions.shape[-1], \n",
    "    'output_size': dataset.num_node_types + 1\n",
    "}\n",
    "\n",
    "\n",
    "graphs_requiring_node_choices = batch.correct_node_type_choices_batch.unique()\n",
    "\n",
    "node_type_selector = GenericMLP(\n",
    "    input_feature_dim = z.shape[-1] + partial_graph_representions.shape[-1],\n",
    "    output_size = dataset.num_node_types,\n",
    ")\n",
    "\n",
    "node_type_selector = GenericMLP(**params['node_type_selector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8408b",
   "metadata": {},
   "source": [
    "### node loss computation in the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0ab3c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = MLPDecoder(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8eb2b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_logits = decoder.pick_node_type(\n",
    "    z,\n",
    "    partial_graph_representions,\n",
    "    graphs_requiring_node_choices = batch.correct_node_type_choices_batch.unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a8a721fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_multihot_labels = []\n",
    "for i in range(len(batch.correct_node_type_choices_ptr)-1):\n",
    "    start_idx = batch.correct_node_type_choices_ptr[i]\n",
    "    end_idx = batch.correct_node_type_choices_ptr[i+1] \n",
    "    if end_idx - start_idx == 0:\n",
    "        continue\n",
    "    node_selection_labels = batch.correct_node_type_choices[start_idx: end_idx]\n",
    "    node_type_multihot_labels += [node_selection_labels]\n",
    "    \n",
    "node_type_multihot_labels = torch.stack(node_type_multihot_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "70656923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4860, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_type_selection_loss = decoder.compute_node_type_selection_loss(\n",
    "    node_logits,\n",
    "    node_type_multihot_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03812ff3",
   "metadata": {},
   "source": [
    "# PickEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd381996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_edge(\n",
    "    input_molecule_representations,\n",
    "    graph_representations,\n",
    "    node_representations,\n",
    "    graph_to_focus_node_map,\n",
    "    node_to_graph_map,\n",
    "    candidate_edge_targets,\n",
    "    candidate_edge_features,\n",
    "    graphs_requiring_node_choices,\n",
    "    partial_graph_start_node_idx, # batch.ptr[:-1]\n",
    "    focus_node_idx_within_each_partial_graph # batch.focus_node\n",
    "):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a2e32e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   8,  17,  27,  37,  47,  58,  69,  81,  93, 106, 124, 134, 153,\n",
       "        172, 192])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ptr[:-1] + batch.focus_node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c411aa85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.focus_node.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "90c22fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.correct_edge_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "edcb7d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False, False, False, False, False,  True, False, False,\n",
       "        False,  True, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.correct_edge_choices != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce597ec",
   "metadata": {},
   "source": [
    "# LightningModule + Vae MLP\n",
    "\n",
    "1. Implement kd divergence loss as part of the lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8364308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molecule_generation.utils.training_utils import get_class_balancing_weights\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "\n",
    "\n",
    "class BaseModel(LightningModule):\n",
    "    def __init__(self, params, dataset):\n",
    "        \"\"\"Params is a nested dictionary with the relevant parameters.\"\"\"\n",
    "        super(BaseModel, self).__init__()\n",
    "        self._init_params(params, dataset)\n",
    "        self._motif_aware_embedding_layer = Embedding(params['motif_aware_embedding'])\n",
    "        self._encoder_gnn = FullGraphEncoder(params['encoder_gnn'])\n",
    "        self._decoder_gnn = PartialGraphEncoder(params['decoder_gnn'])\n",
    "        self._decoder_mlp = MLPDecoder(params['decoder_mlp'])\n",
    "        \n",
    "        # params for latent space\n",
    "        self._latent_sample_strategy = params['latent_sample_strategy']\n",
    "        self._latent_repr_dim = params[\"latent_repr_size\"]\n",
    "        \n",
    "        \n",
    "               \n",
    "    def _init_params(self, params, dataset):\n",
    "        \"\"\"\n",
    "        Initialise class weights for next node prediction and placefolder for\n",
    "        motif/node embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get some information out from the dataset:\n",
    "        next_node_type_distribution = dataset.metadata.get(\"train_next_node_type_distribution\")\n",
    "        class_weight_factor = self._params.get(\"node_type_predictor_class_loss_weight_factor\", 0.0)\n",
    "        \n",
    "        if not (0.0 <= class_weight_factor <= 1.0):\n",
    "            raise ValueError(\n",
    "                f\"Node class loss weight node_classifier_class_loss_weight_factor must be in [0,1], but is {class_weight_factor}!\"\n",
    "            )\n",
    "        if class_weight_factor > 0:\n",
    "            atom_type_nums = [\n",
    "                next_node_type_distribution[dataset.node_type_index_to_string[type_idx]]\n",
    "                for type_idx in range(dataset.num_node_types)\n",
    "            ]\n",
    "            atom_type_nums.append(next_node_type_distribution[\"None\"])\n",
    "\n",
    "            self.class_weights = get_class_balancing_weights(\n",
    "                class_counts=atom_type_nums, class_weight_factor=class_weight_factor\n",
    "            )\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "            \n",
    "        motif_vocabulary = dataset.metadata.get(\"motif_vocabulary\")\n",
    "        self._uses_motifs = motif_vocabulary is not None\n",
    "\n",
    "        self._node_categorical_num_classes = dataset.node_categorical_num_classes\n",
    "        \n",
    "        \n",
    "        if self.uses_categorical_features:\n",
    "            if \"categorical_features_embedding_dim\" in self._params:\n",
    "                self._node_categorical_features_embedding = None\n",
    "        \n",
    "    @property\n",
    "    def uses_motifs(self):\n",
    "        return self._uses_motifs\n",
    "\n",
    "    @property\n",
    "    def uses_categorical_features(self):\n",
    "        return self._node_categorical_num_classes is not None\n",
    "\n",
    "    @property\n",
    "    def decoder(self):\n",
    "        return self._decoder\n",
    "\n",
    "    @property\n",
    "    def encoder(self):\n",
    "        return self._encoder\n",
    "    \n",
    "    @property\n",
    "    def motif_aware_embedding_layer(self):\n",
    "        return self._motif_aware_embedding_layer\n",
    "    \n",
    "    @property\n",
    "    def latent_dim(self):\n",
    "        return self._latent_repr_dim\n",
    "    \n",
    "    def compute_initial_node_features(batch )\n",
    "        # Compute embedding\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def sample_from_latent_repr(latent_repr):\n",
    "        # perturb latent repr\n",
    "        mu = latent_repr[:, : self.latent_dim]  # Shape: [V, MD]\n",
    "        log_var = latent_repr[:, self.latent_dim :]  # Shape: [V, MD]\n",
    "\n",
    "        # result_representations: shape [num_partial_graphs, latent_repr_dim]\n",
    "        p, q, z = self.sample(mu, log_var)\n",
    "        \n",
    "        return p, q, z \n",
    "        \n",
    "    def sample(self, mu, log_var)\n",
    "        \"\"\"Samples a different noise vector for each partial graph. \n",
    "        TODO: look into the other sampling strategies.\"\"\"\n",
    "        std = torch.exp(log_var / 2)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "        return p, q, z\n",
    "    \n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch, ??):\n",
    "        # Obtain node embeddings \n",
    "        batch = self.compute_initial_node_features(batch)\n",
    "        \n",
    "        # Forward pass through encoder\n",
    "        latent_repr = self.encoder(batch)\n",
    "        \n",
    "        # Apply latent sampling strategy\n",
    "        p, q, latent_repr = self.sample_from_latent_repr(latent_repr)\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        node_type_logits, edge_candidate_logits, edge_type_logits, attachment_point_selection_logits = self.decoder(latent_repr)\n",
    "        \n",
    "        # NOTE: loss computation will be done in lightning module\n",
    "        return MoLeROutput(\n",
    "            node_type_logits = node_type_logits,\n",
    "            edge_candidate_logits = edge_candidate_logits,\n",
    "            edge_type_logits = edge_type_logits,\n",
    "            attachment_point_selection_logits = attachment_point_selection_logits,\n",
    "            p = p,\n",
    "            q = q,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a0103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257f1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
