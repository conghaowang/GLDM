{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5caa28ca",
   "metadata": {},
   "source": [
    "# Design \n",
    "\n",
    "1. All model related loss computations and helper functions are in torch.modules and they will all be called compute_loss \n",
    "2. The MLPDecoder will house all the MLPs involved in the decoder and will have 1 compute_decoder_loss_method that will call all the individual compute_loss methods.\n",
    "\n",
    "It will also have a decode method that will do decoding at inference time(TODO)\n",
    "\n",
    "3. The FullGraphEncoder and the PartialGraphEncoder will each be in their own torch modules\n",
    "\n",
    "4. Finally, the lightning module will have 3 things: \n",
    "- FullGraphEncoder\n",
    "- PartialGraphEncoder (part of decoder)\n",
    "- MLPDecoder\n",
    "\n",
    "And after passing through the initial FullGraphEncoder, if we are working with a VAE, we will extract p and q for computing the kl divergence loss, otherwise we will do the other model specific stuff like diffusion.\n",
    "\n",
    "`params` dictionary will be passed to the lightning module and each torch module will be constructed within it using the relevant parameters by destructuring the dictionary \n",
    "\n",
    "node type class weights will be instantiated in the lightning module and passed to the decoder\n",
    "\n",
    "# TODO\n",
    "1. fix the incrementing in the original graph edge index (DONE)\n",
    "2. Work on first node prediction \n",
    "3. Investigate node_type_predictor_class_loss_weight_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c82689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params houses all relevant model instantiation parameters\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75459146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import MolerDataset, MolerData\n",
    "from utils import pprint_pyg_obj\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50a5acbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:12:52.696562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dataset = MolerDataset(\n",
    "    root = '/data/ongh0068', \n",
    "    raw_moler_trace_dataset_parent_folder = '/data/ongh0068/l1000/trace_playground',\n",
    "    output_pyg_trace_dataset_parent_folder = '/data/ongh0068/l1000/pyg_output_playground',\n",
    "    split = 'train',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b80108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=16, shuffle=False, follow_batch = [\n",
    "    'correct_edge_choices',\n",
    "    'correct_edge_types',\n",
    "    'valid_edge_choices',\n",
    "    'valid_attachment_point_choices',\n",
    "    'correct_attachment_point_choice',\n",
    "    'correct_node_type_choices',\n",
    "    'original_graph_x'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340217e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea61240",
   "metadata": {},
   "source": [
    "# FullGraphEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728b29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericGraphEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59373d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(torch.nn.Module):\n",
    "    \"\"\"Returns graph level representation of the molecules.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_feature_dim,\n",
    "        atom_or_motif_vocab_size,\n",
    "        motif_embedding_size = 64,\n",
    "        hidden_layer_feature_dim=64,\n",
    "        num_layers=12,\n",
    "        layer_type=\"RGATConv\",\n",
    "        use_intermediate_gnn_results=True,\n",
    "    ):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self._embed = torch.nn.Embedding(atom_or_motif_vocab_size, motif_embedding_size)\n",
    "        self._model = GenericGraphEncoder(input_feature_dim = motif_embedding_size + input_feature_dim)\n",
    "        \n",
    "    def forward(self, original_graph_node_categorical_features, node_features, edge_index, edge_type, batch_index):\n",
    "        motif_embeddings = self._embed(original_graph_node_categorical_features)\n",
    "        node_features = torch.cat((node_features, motif_embeddings), axis = -1)\n",
    "        input_molecule_representations, _ = self._model(node_features, edge_index.long(), edge_type, batch_index)\n",
    "        return input_molecule_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ca9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['full_graph_encoder'] = {\n",
    "    'input_feature_dim': batch.x.shape[-1],\n",
    "    'atom_or_motif_vocab_size': len(dataset.node_type_index_to_string)\n",
    "}\n",
    "\n",
    "full_graph_encoder = GraphEncoder(\n",
    "    input_feature_dim = batch.x.shape[-1],\n",
    "    atom_or_motif_vocab_size = len(dataset.node_type_index_to_string)\n",
    ")\n",
    "\n",
    "full_graph_encoder = GraphEncoder(**params['full_graph_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f6eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_molecule_representations = full_graph_encoder(\n",
    "    batch.original_graph_node_categorical_features, \n",
    "    batch.original_graph_x.float(),\n",
    "    batch.original_graph_edge_index,\n",
    "    batch.original_graph_edge_type,\n",
    "    batch_index = batch.original_graph_x_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be236a",
   "metadata": {},
   "source": [
    "# PartialGraphEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc2ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['partial_graph_encoder'] = {\n",
    "    'input_feature_dim': batch.x.shape[-1],\n",
    "}\n",
    "\n",
    "partial_graph_encoder = GenericGraphEncoder(\n",
    "    input_feature_dim = batch.x.shape[-1],\n",
    ")\n",
    "\n",
    "partial_graph_encoder = GenericGraphEncoder(**params['partial_graph_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86d6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_graph_representions, node_representations = partial_graph_encoder(batch.x, batch.edge_index.long(), batch.edge_type, batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb0cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([193, 832])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37317282",
   "metadata": {},
   "source": [
    "# _mean_log_var_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c80a78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericMLP\n",
    "latent_dim = 512\n",
    "params['mean_log_var_mlp'] = {\n",
    "    'input_feature_dim': input_molecule_representations.shape[-1],\n",
    "    'output_size': latent_dim * 2\n",
    "}\n",
    "\n",
    "\n",
    "mean_log_var_mlp = GenericMLP(**params['mean_log_var_mlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1396e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_and_log_var = mean_log_var_mlp(input_molecule_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eec0a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = mean_and_log_var[:, : latent_dim]  # Shape: [V, MD]\n",
    "log_var = mean_and_log_var[:, latent_dim :]  # Shape: [V, MD]\n",
    "\n",
    "# result_representations: shape [num_partial_graphs, latent_repr_dim]\n",
    "std = torch.exp(log_var / 2)\n",
    "p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "q = torch.distributions.Normal(mu, std)\n",
    "z = q.rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "149bc619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c5e05",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "de6b929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder import MLPDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b171e",
   "metadata": {},
   "source": [
    "## PickAtomOrMotif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c283c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molecule_generation.utils.training_utils import get_class_balancing_weights\n",
    "\n",
    "\n",
    "next_node_type_distribution = dataset.metadata.get(\"train_next_node_type_distribution\")\n",
    "class_weight_factor = params.get(\"node_type_predictor_class_loss_weight_factor\", 1.0)\n",
    "\n",
    "if not (0.0 <= class_weight_factor <= 1.0):\n",
    "    raise ValueError(\n",
    "        f\"Node class loss weight node_classifier_class_loss_weight_factor must be in [0,1], but is {class_weight_factor}!\"\n",
    "    )\n",
    "if class_weight_factor > 0:\n",
    "    atom_type_nums = [\n",
    "        next_node_type_distribution[dataset.node_type_index_to_string[type_idx]]\n",
    "        for type_idx in range(dataset.num_node_types)\n",
    "    ]\n",
    "    atom_type_nums.append(next_node_type_distribution[\"None\"])\n",
    "\n",
    "    class_weights = get_class_balancing_weights(\n",
    "        class_counts=atom_type_nums, class_weight_factor=class_weight_factor\n",
    "    )\n",
    "else:\n",
    "    class_weights = None\n",
    "    \n",
    "    \n",
    "    \n",
    "params['node_type_loss_weights'] = torch.tensor(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11ae57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GenericMLP\n",
    "params['node_type_selector'] = {\n",
    "    'input_feature_dim':  z.shape[-1] + partial_graph_representions.shape[-1], \n",
    "    'output_size': dataset.num_node_types + 1\n",
    "}\n",
    "\n",
    "\n",
    "graphs_requiring_node_choices = batch.correct_node_type_choices_batch.unique()\n",
    "\n",
    "node_type_selector = GenericMLP(\n",
    "    input_feature_dim = z.shape[-1] + partial_graph_representions.shape[-1],\n",
    "    output_size = dataset.num_node_types,\n",
    ")\n",
    "\n",
    "node_type_selector = GenericMLP(**params['node_type_selector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8408b",
   "metadata": {},
   "source": [
    "### node loss computation in the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ab3c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = MLPDecoder(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8eb2b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_logits = decoder.pick_node_type(\n",
    "    z,\n",
    "    partial_graph_representions,\n",
    "    graphs_requiring_node_choices = batch.correct_node_type_choices_batch.unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8a721fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_multihot_labels = []\n",
    "for i in range(len(batch.correct_node_type_choices_ptr)-1):\n",
    "    start_idx = batch.correct_node_type_choices_ptr[i]\n",
    "    end_idx = batch.correct_node_type_choices_ptr[i+1] \n",
    "    if end_idx - start_idx == 0:\n",
    "        continue\n",
    "    node_selection_labels = batch.correct_node_type_choices[start_idx: end_idx]\n",
    "    node_type_multihot_labels += [node_selection_labels]\n",
    "    \n",
    "node_type_multihot_labels = torch.stack(node_type_multihot_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "70656923",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_selection_loss = decoder.compute_node_type_selection_loss(\n",
    "    node_logits,\n",
    "    node_type_multihot_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03812ff3",
   "metadata": {},
   "source": [
    "# PickEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ad35cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params['no_more_edges_repr'] = (1,node_representations.shape[-1] + batch.edge_features.shape[-1])\n",
    "params['edge_candidate_scorer'] = {\n",
    "    'input_feature_dim': 3331,\n",
    "    'output_size': 1\n",
    "}\n",
    "\n",
    "params['edge_type_selector'] = {\n",
    "    'input_feature_dim': 3331,\n",
    "    'output_size': 3\n",
    "}\n",
    "\n",
    "\n",
    "_no_more_edges_representation = torch.nn.Parameter(torch.FloatTensor(*params['no_more_edges_repr']), requires_grad = True)\n",
    "_edge_candidate_scorer = GenericMLP(**params['edge_candidate_scorer'])\n",
    "_edge_type_selector = GenericMLP(**params['edge_type_selector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2e32e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5850, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from decoder import MLPDecoder\n",
    "decoder = MLPDecoder(params)\n",
    "edge_candidate_logits, edge_type_logits = decoder.pick_edge(\n",
    "    input_molecule_representations,\n",
    "    partial_graph_representions,\n",
    "    node_representations,\n",
    "    num_graphs_in_batch = len(batch.ptr) - 1,\n",
    "    graph_to_focus_node_map= batch.focus_node,\n",
    "    node_to_graph_map=batch.batch,\n",
    "    candidate_edge_targets= batch.valid_edge_choices[:, 1].long(),\n",
    "    candidate_edge_features= batch.edge_features\n",
    ")\n",
    "decoder.compute_edge_candidate_selection_loss(\n",
    "    num_graphs_in_batch= len(batch.ptr)-1,\n",
    "    node_to_graph_map=batch.batch,\n",
    "    candidate_edge_targets= batch.valid_edge_choices[:, 1].long(),\n",
    "    edge_candidate_logits = edge_candidate_logits, # as is\n",
    "    per_graph_num_correct_edge_choices= batch.num_correct_edge_choices,\n",
    "    edge_candidate_correctness_labels = batch.correct_edge_choices,\n",
    "    no_edge_selected_labels = batch.stop_node_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09fc54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce597ec",
   "metadata": {},
   "source": [
    "# LightningModule + Vae MLP\n",
    "\n",
    "1. Implement kd divergence loss as part of the lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8364308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molecule_generation.utils.training_utils import get_class_balancing_weights\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "\n",
    "\n",
    "class BaseModel(LightningModule):\n",
    "    def __init__(self, params, dataset):\n",
    "        \"\"\"Params is a nested dictionary with the relevant parameters.\"\"\"\n",
    "        super(BaseModel, self).__init__()\n",
    "        self._init_params(params, dataset)\n",
    "        self._motif_aware_embedding_layer = Embedding(params['motif_aware_embedding'])\n",
    "        self._encoder_gnn = FullGraphEncoder(params['encoder_gnn'])\n",
    "        self._decoder_gnn = PartialGraphEncoder(params['decoder_gnn'])\n",
    "        self._decoder_mlp = MLPDecoder(params['decoder_mlp'])\n",
    "        \n",
    "        # params for latent space\n",
    "        self._latent_sample_strategy = params['latent_sample_strategy']\n",
    "        self._latent_repr_dim = params[\"latent_repr_size\"]\n",
    "        \n",
    "        \n",
    "               \n",
    "    def _init_params(self, params, dataset):\n",
    "        \"\"\"\n",
    "        Initialise class weights for next node prediction and placefolder for\n",
    "        motif/node embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get some information out from the dataset:\n",
    "        next_node_type_distribution = dataset.metadata.get(\"train_next_node_type_distribution\")\n",
    "        class_weight_factor = self._params.get(\"node_type_predictor_class_loss_weight_factor\", 0.0)\n",
    "        \n",
    "        if not (0.0 <= class_weight_factor <= 1.0):\n",
    "            raise ValueError(\n",
    "                f\"Node class loss weight node_classifier_class_loss_weight_factor must be in [0,1], but is {class_weight_factor}!\"\n",
    "            )\n",
    "        if class_weight_factor > 0:\n",
    "            atom_type_nums = [\n",
    "                next_node_type_distribution[dataset.node_type_index_to_string[type_idx]]\n",
    "                for type_idx in range(dataset.num_node_types)\n",
    "            ]\n",
    "            atom_type_nums.append(next_node_type_distribution[\"None\"])\n",
    "\n",
    "            self.class_weights = get_class_balancing_weights(\n",
    "                class_counts=atom_type_nums, class_weight_factor=class_weight_factor\n",
    "            )\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "            \n",
    "        motif_vocabulary = dataset.metadata.get(\"motif_vocabulary\")\n",
    "        self._uses_motifs = motif_vocabulary is not None\n",
    "\n",
    "        self._node_categorical_num_classes = dataset.node_categorical_num_classes\n",
    "        \n",
    "        \n",
    "        if self.uses_categorical_features:\n",
    "            if \"categorical_features_embedding_dim\" in self._params:\n",
    "                self._node_categorical_features_embedding = None\n",
    "        \n",
    "    @property\n",
    "    def uses_motifs(self):\n",
    "        return self._uses_motifs\n",
    "\n",
    "    @property\n",
    "    def uses_categorical_features(self):\n",
    "        return self._node_categorical_num_classes is not None\n",
    "\n",
    "    @property\n",
    "    def decoder(self):\n",
    "        return self._decoder\n",
    "\n",
    "    @property\n",
    "    def encoder(self):\n",
    "        return self._encoder\n",
    "    \n",
    "    @property\n",
    "    def motif_aware_embedding_layer(self):\n",
    "        return self._motif_aware_embedding_layer\n",
    "    \n",
    "    @property\n",
    "    def latent_dim(self):\n",
    "        return self._latent_repr_dim\n",
    "    \n",
    "    def compute_initial_node_features(batch )\n",
    "        # Compute embedding\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def sample_from_latent_repr(latent_repr):\n",
    "        # perturb latent repr\n",
    "        mu = latent_repr[:, : self.latent_dim]  # Shape: [V, MD]\n",
    "        log_var = latent_repr[:, self.latent_dim :]  # Shape: [V, MD]\n",
    "\n",
    "        # result_representations: shape [num_partial_graphs, latent_repr_dim]\n",
    "        p, q, z = self.sample(mu, log_var)\n",
    "        \n",
    "        return p, q, z \n",
    "        \n",
    "    def sample(self, mu, log_var)\n",
    "        \"\"\"Samples a different noise vector for each partial graph. \n",
    "        TODO: look into the other sampling strategies.\"\"\"\n",
    "        std = torch.exp(log_var / 2)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "        return p, q, z\n",
    "    \n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch, ??):\n",
    "        # Obtain node embeddings \n",
    "        batch = self.compute_initial_node_features(batch)\n",
    "        \n",
    "        # Forward pass through encoder\n",
    "        latent_repr = self.encoder(batch)\n",
    "        \n",
    "        # Apply latent sampling strategy\n",
    "        p, q, latent_repr = self.sample_from_latent_repr(latent_repr)\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        node_type_logits, edge_candidate_logits, edge_type_logits, attachment_point_selection_logits = self.decoder(latent_repr)\n",
    "        \n",
    "        # NOTE: loss computation will be done in lightning module\n",
    "        return MoLeROutput(\n",
    "            node_type_logits = node_type_logits,\n",
    "            edge_candidate_logits = edge_candidate_logits,\n",
    "            edge_type_logits = edge_type_logits,\n",
    "            attachment_point_selection_logits = attachment_point_selection_logits,\n",
    "            p = p,\n",
    "            q = q,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a0103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257f1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
