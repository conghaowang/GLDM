{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38c7e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 00:32:42.495625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model import BaseModel\n",
    "from dataset import MolerDataset, MolerData\n",
    "from utils import pprint_pyg_obj\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from model_utils import get_params\n",
    "\n",
    "\n",
    "\n",
    "dataset = MolerDataset(\n",
    "    root = '/data/ongh0068', \n",
    "    raw_moler_trace_dataset_parent_folder = '/data/ongh0068/guacamol/trace_dir',\n",
    "    output_pyg_trace_dataset_parent_folder = '/data/ongh0068/l1000/pyg_output_playground',\n",
    "    split = 'train_0',\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=False, follow_batch = [\n",
    "    'correct_edge_choices',\n",
    "    'correct_edge_types',\n",
    "    'valid_edge_choices',\n",
    "    'valid_attachment_point_choices',\n",
    "    'correct_attachment_point_choice',\n",
    "    'correct_node_type_choices',\n",
    "    'original_graph_x',\n",
    "    'correct_first_node_type_choices'\n",
    "])\n",
    "params = get_params(dataset)\n",
    "\n",
    "for batch in loader:\n",
    "#     batch.cuda()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f70360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_graph_encoder': {'input_feature_dim': 59,\n",
       "  'atom_or_motif_vocab_size': 166},\n",
       " 'partial_graph_encoder': {'input_feature_dim': 59,\n",
       "  'atom_or_motif_vocab_size': 166},\n",
       " 'mean_log_var_mlp': {'input_feature_dim': 832, 'output_size': 1024},\n",
       " 'decoder': {'node_type_selector': {'input_feature_dim': 1344,\n",
       "   'output_size': 167},\n",
       "  'node_type_loss_weights': tensor([5.5000, 0.5500, 2.2489, 0.5500, 0.5500, 0.7156, 0.8666, 0.7145, 5.5000,\n",
       "          1.8568, 2.1470, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
       "          5.5000, 5.5000, 5.5000, 5.5000], device='cuda:0'),\n",
       "  'no_more_edges_repr': (1, 835),\n",
       "  'edge_candidate_scorer': {'input_feature_dim': 3011, 'output_size': 1},\n",
       "  'edge_type_selector': {'input_feature_dim': 3011, 'output_size': 3},\n",
       "  'attachment_point_selector': {'input_feature_dim': 2176, 'output_size': 1},\n",
       "  'first_node_type_selector': {'input_feature_dim': 512, 'output_size': 166}},\n",
       " 'latent_sample_strategy': 'per_graph',\n",
       " 'latent_repr_dim': 512,\n",
       " 'latent_repr_size': 512}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04fc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(params, dataset)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bb7f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphEncoder(\n",
       "  (_embed): Embedding(166, 64)\n",
       "  (_model): GenericGraphEncoder(\n",
       "    (_first_layer): RGATConv(123, 64, heads=1)\n",
       "    (_encoder_layers): ModuleList(\n",
       "      (0): RGATConv(64, 64, heads=1)\n",
       "      (1): RGATConv(64, 64, heads=1)\n",
       "      (2): RGATConv(64, 64, heads=1)\n",
       "      (3): RGATConv(64, 64, heads=1)\n",
       "      (4): RGATConv(64, 64, heads=1)\n",
       "      (5): RGATConv(64, 64, heads=1)\n",
       "      (6): RGATConv(64, 64, heads=1)\n",
       "      (7): RGATConv(64, 64, heads=1)\n",
       "      (8): RGATConv(64, 64, heads=1)\n",
       "      (9): RGATConv(64, 64, heads=1)\n",
       "      (10): RGATConv(64, 64, heads=1)\n",
       "      (11): RGATConv(64, 64, heads=1)\n",
       "    )\n",
       "    (_softmax_aggr): SoftmaxAggregation(learn=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._full_graph_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e5ac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.node_type_index_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52459ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input_molecule_representations = model._full_graph_encoder(\n",
    "        original_graph_node_categorical_features=batch.original_graph_node_categorical_features,\n",
    "        node_features=batch.original_graph_x.float(),\n",
    "        edge_index=batch.original_graph_edge_index,\n",
    "        edge_type=batch.original_graph_edge_type.int(),\n",
    "        batch_index=batch.original_graph_x_batch,\n",
    "    )\n",
    "\n",
    "\n",
    "    partial_graph_representions, node_representations = model._partial_graph_encoder(\n",
    "        partial_graph_node_categorical_features = batch.partial_node_categorical_features,\n",
    "        node_features = batch.x,\n",
    "        edge_index = batch.edge_index.long(), \n",
    "        edge_type = batch.edge_type, \n",
    "        graph_to_focus_node_map = batch.focus_node,\n",
    "        candidate_attachment_points = batch.valid_attachment_point_choices,\n",
    "        batch_index = batch.batch\n",
    "    )\n",
    "    # Apply latent sampling strategy\n",
    "    p, q, latent_representations = model.sample_from_latent_repr(\n",
    "        input_molecule_representations\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0963d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b48bc63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n",
      "RDKit runtime error on base molecule, with message:\n",
      "unsupported operand type(s) for -: '_vectSt6vectorIiSaIiEE' and '_vectSt6vectorIiSaIiEE'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index_select(): Expected dtype int32 or int64 for index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decoder_states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_representations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlatent_representations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ongh0068/l1000/FYP-DrugDiscoveryWithDeepLearning/model.py:910\u001b[0m, in \u001b[0;36mBaseModel.decode\u001b[0;34m(self, latent_representations, initial_molecules, mol_ids, store_generation_traces, max_num_steps, beam_size, sampling_mode)\u001b[0m\n\u001b[1;32m    904\u001b[0m require_bond_states \u001b[38;5;241m=\u001b[39m restrict_to_beam_size_per_mol(require_bond_states, beam_size)\n\u001b[1;32m    905\u001b[0m bond_pick_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder_pick_new_bond_types(\n\u001b[1;32m    906\u001b[0m     decoder_states\u001b[38;5;241m=\u001b[39mrequire_bond_states,\n\u001b[1;32m    907\u001b[0m     store_generation_traces\u001b[38;5;241m=\u001b[39mstore_generation_traces,\n\u001b[1;32m    908\u001b[0m     sampling_mode\u001b[38;5;241m=\u001b[39msampling_mode,\n\u001b[1;32m    909\u001b[0m )\n\u001b[0;32m--> 910\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (decoder_state, (bond_picks, edge_choice_info)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    911\u001b[0m     require_bond_states, bond_pick_results\n\u001b[1;32m    912\u001b[0m ):\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bond_picks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# There were no valid options for this bonds, so we treat this as if\u001b[39;00m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;66;03m# predicting no more bonds with probability 1.0:\u001b[39;00m\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;66;03m# print(I {decoder_state.molecule_id} {decoder_state.logprob:12f}: No more allowed bonds to node {decoder_state.focus_atom}\")\u001b[39;00m\n\u001b[1;32m    917\u001b[0m         new_decoder_states\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    918\u001b[0m             MoLeRDecoderState\u001b[38;5;241m.\u001b[39mnew_with_focus_marked_as_visited(\n\u001b[1;32m    919\u001b[0m                 decoder_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m             )\n\u001b[1;32m    923\u001b[0m         )\n",
      "File \u001b[0;32m/data/ongh0068/l1000/FYP-DrugDiscoveryWithDeepLearning/model.py:654\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_state_features\n\u001b[1;32m    645\u001b[0m batch_generator \u001b[38;5;241m=\u001b[39m batch_decoder_states(\n\u001b[1;32m    646\u001b[0m     decoder_states\u001b[38;5;241m=\u001b[39mdecoder_states,\n\u001b[1;32m    647\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    650\u001b[0m     add_state_to_batch_callback\u001b[38;5;241m=\u001b[39madd_state_to_edge_batch,\n\u001b[1;32m    651\u001b[0m )\n\u001b[1;32m    653\u001b[0m picked_edges_generator \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pick_edges_for_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_generation_traces\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b, d \u001b[38;5;129;01min\u001b[39;00m batch_generator\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(picked_edges_generator)\n",
      "File \u001b[0;32m/data/ongh0068/l1000/FYP-DrugDiscoveryWithDeepLearning/model.py:482\u001b[0m, in \u001b[0;36mBaseModel._pick_edges_for_batch\u001b[0;34m(self, batch, decoder_states, num_samples, sampling_mode, store_generation_traces)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pick_edges_for_batch\u001b[39m(\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    475\u001b[0m     batch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m     store_generation_traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    480\u001b[0m ):\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 482\u001b[0m         graph_representations, node_representations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_graph_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpartial_graph_node_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m            \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m            \u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Here we choose an arbitrary attachment point as a focus atom; this does not matter\u001b[39;49;00m\n\u001b[1;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# since later all candidate attachment points are marked with the in-focus bit.\u001b[39;49;00m\n\u001b[1;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgraph_to_focus_node_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfocus_atoms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcandidate_attachment_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m         batch_candidate_edge_targets \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mcandidate_edge_targets\n\u001b[1;32m    495\u001b[0m         batch_candidate_edge_type_masks \u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mcandidate_edge_type_masks\n",
      "File \u001b[0;32m/data/ongh0068/anaconda3/envs/l1000/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/ongh0068/l1000/FYP-DrugDiscoveryWithDeepLearning/encoder.py:99\u001b[0m, in \u001b[0;36mPartialGraphEncoder.forward\u001b[0;34m(self, partial_graph_node_categorical_features, node_features, edge_index, edge_type, graph_to_focus_node_map, candidate_attachment_points, batch_index)\u001b[0m\n\u001b[1;32m     96\u001b[0m node_is_in_focus_bit \u001b[38;5;241m=\u001b[39m node_is_in_focus_bit\u001b[38;5;241m.\u001b[39mminimum(torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdummy_param\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m     97\u001b[0m initial_node_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([initial_node_features, node_is_in_focus_bit], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m partial_graph_representions, node_representations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_node_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m partial_graph_representions, node_representations\n",
      "File \u001b[0;32m/data/ongh0068/anaconda3/envs/l1000/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/ongh0068/l1000/FYP-DrugDiscoveryWithDeepLearning/model_utils.py:63\u001b[0m, in \u001b[0;36mGenericGraphEncoder.forward\u001b[0;34m(self, node_features, edge_index, edge_type, batch_index)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_features, edge_index, edge_type, batch_index):\n\u001b[1;32m     62\u001b[0m     gnn_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 63\u001b[0m     gnn_results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder_layers):\n\u001b[1;32m     66\u001b[0m         gnn_results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [layer(gnn_results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], edge_index\u001b[38;5;241m.\u001b[39mlong(), edge_type)]\n",
      "File \u001b[0;32m/data/ongh0068/anaconda3/envs/l1000/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/ongh0068/anaconda3/envs/l1000/lib/python3.9/site-packages/torch_geometric/nn/conv/rgat_conv.py:341\u001b[0m, in \u001b[0;36mRGATConv.forward\u001b[0;34m(self, x, edge_index, edge_type, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m    x (Tensor): The input node features. Can be either a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m        attention weights for each edge. (default: :obj:`None`)\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_type: OptTensor, edge_attr: OptTensor)  # noqa\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/ongh0068/anaconda3/envs/l1000/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:437\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 437\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    439\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/data/ongh0068/anaconda3/envs/l1000/lib/python3.9/site-packages/torch_geometric/nn/conv/rgat_conv.py:380\u001b[0m, in \u001b[0;36mRGATConv.message\u001b[0;34m(self, x_i, x_j, edge_type, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bases \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\n\u001b[0;32m--> 380\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m outi \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(x_i\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), w)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    382\u001b[0m outj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(x_j\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), w)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index_select(): Expected dtype int32 or int64 for index"
     ]
    }
   ],
   "source": [
    "decoder_states = model.decode(latent_representations = latent_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e62386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mChem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Draw\n\u001b[0;32m----> 2\u001b[0m Draw\u001b[38;5;241m.\u001b[39mMolsToGridImage([decoder_states[i]\u001b[38;5;241m.\u001b[39mmolecule \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdecoder_states\u001b[49m))], subImgSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m1000\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_states' is not defined"
     ]
    }
   ],
   "source": [
    "from rdkit.Chem import Draw\n",
    "Draw.MolsToGridImage([decoder_states[i].molecule for i in range(len(decoder_states))], subImgSize=(1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6992ef0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCC(=O)O.CCCC(=O)NC1(CC#N)C23CC4=NN5C(=O)C67C8=C9OC%10C%11=C%12CC(=O)OS(=O)(=O)C1%13OC1C%14CNCC1%15C%13=C(CC(=O)O)N1C%13%16OC(=O)C(C)C%17%18ON=C%19OC(=O)C(OC(=O)CC)(OC(=O)CCC%20(CCOC(=C(CC(=O)O)N(CCC2O4)C3)C%20)C%17(C(=O)O)S%10(=O)=O)C62ON=C3C%12C(=O)N4OC(=O)C6CC%11%13C9C6(COC6CCCOC6)NC(CC(=O)O)=NCCOC69C%10CC%11(CN6C5(C)C(=O)O)C56OC%12%13C5(C(=O)N5C(=C=NOC5(C)C(=O)O2)C(=O)OS(=O)(=O)C(CN2CCCC2)C(=O)O%10)C1(OC(=O)CC)C%12(C4(C(=O)O%19)C%11%16%13)C61C(N)(CO)OC(=O)C1(C%15%18)C81OC(OC(=O)C(C)=C(C)CC(=O)NCCC#N)C(=C(COC(=O)CC)C(=O)O)C1C1(C2CN(C(=C=NO)C(C2=C(C)C(=O)O)C%149N(C)CC)C12CCNCC2)N37.NCCO'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "Chem.MolToSmiles(decoder_states[1].molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74502a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
