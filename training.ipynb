{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e744607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/data/ongh0068/l1000/pyg_output_playground/train/processed_file_paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8a087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/data/ongh0068/l1000/moler_reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac216788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 12:03:06.465911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "from molecule_generation.chem.motif_utils import get_motif_type_to_node_type_index_map\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def get_motif_type_to_node_type_index_map(\n",
    "    motif_vocabulary, num_atom_types\n",
    "):\n",
    "    \"\"\"Helper to construct a mapping from motif type to shifted node type.\"\"\"\n",
    "\n",
    "    return {\n",
    "        motif: num_atom_types + motif_type\n",
    "        for motif, motif_type in motif_vocabulary.vocabulary.items()\n",
    "    }\n",
    "\n",
    "\n",
    "class MolerDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root, \n",
    "        raw_moler_trace_dataset_parent_folder, # absolute path \n",
    "        output_pyg_trace_dataset_parent_folder, # absolute path\n",
    "        split = 'train',\n",
    "        transform=None, \n",
    "        pre_transform=None, \n",
    "    ):\n",
    "        self._processed_file_paths = None\n",
    "        self._transform = transform \n",
    "        self._pre_transform = pre_transform\n",
    "        self._raw_moler_trace_dataset_parent_folder = raw_moler_trace_dataset_parent_folder\n",
    "        self._output_pyg_trace_dataset_parent_folder = output_pyg_trace_dataset_parent_folder\n",
    "        self._split = split\n",
    "        self.load_metadata()\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\"\n",
    "        Raw generation trace files output from the preprocess function of the cli. These are zipped pickle\n",
    "        files. This is the actual file name without the parent folder.\n",
    "        \"\"\"\n",
    "        raw_pkl_file_folders = [folder for folder in os.listdir(self._raw_moler_trace_dataset_parent_folder) if folder.startswith(self._split)]\n",
    "\n",
    "        assert len(raw_pkl_file_folders) > 0, f'{self._raw_moler_trace_dataset_parent_folder} does not contain {self._split} files.'\n",
    "        \n",
    "        raw_generation_trace_files = []\n",
    "        for folder in raw_pkl_file_folders:\n",
    "            for pkl_file in os.listdir(os.path.join(self._raw_moler_trace_dataset_parent_folder, folder)):\n",
    "                raw_generation_trace_files.append(os.path.join(self._raw_moler_trace_dataset_parent_folder, folder, pkl_file))\n",
    "        return raw_generation_trace_files\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"Processed generation trace objects that are stored as .pt files\"\"\"\n",
    "        processed_file_paths_folder = os.path.join(self._output_pyg_trace_dataset_parent_folder, self._split)\n",
    "        if self._processed_file_paths is not None:\n",
    "            return self._processed_file_paths\n",
    "        \n",
    "        if not os.path.exists(processed_file_paths_folder):\n",
    "            os.mkdir(processed_file_paths_folder)\n",
    "            \n",
    "        # After processing, the file paths will be saved in the csv file \n",
    "        processed_file_paths_csv = os.path.join(processed_file_paths_folder, 'processed_file_paths.csv')\n",
    "\n",
    "        if not os.path.exists(processed_file_paths_csv):\n",
    "            is_csv_generated = self._generate_processed_file_paths_csv(processed_file_paths_folder, processed_file_paths_csv)\n",
    "            if not is_csv_generated:\n",
    "                return []\n",
    "        self._processed_file_paths = pd.read_csv(processed_file_paths_csv)['file_names'].tolist()\n",
    "        return self._processed_file_paths \n",
    "\n",
    "    def _generate_processed_file_paths_csv(self, processed_file_paths_folder, processed_file_paths_csv):\n",
    "        \n",
    "        file_paths = [os.path.join(processed_file_paths_folder, file_path) for file_path in os.listdir(processed_file_paths_folder)]\n",
    "        if len(file_paths) > 0:\n",
    "            df = pd.DataFrame(file_paths, columns = ['file_names'])\n",
    "            df.to_csv(processed_file_paths_csv, index = False)\n",
    "            return True\n",
    "        else:\n",
    "            print('No processed files found!')\n",
    "\n",
    "    @property\n",
    "    def processed_file_names_size(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    @property \n",
    "    def metadata(self):\n",
    "        return self._metadata\n",
    "\n",
    "    @property\n",
    "    def node_type_index_to_string(self):\n",
    "        return self._node_type_index_to_string\n",
    "    \n",
    "    @property \n",
    "    def num_node_types(self):\n",
    "        return len(self.node_type_index_to_string)\n",
    "\n",
    "    def node_type_to_index(self, node_type):\n",
    "        return self._atom_type_featuriser.type_name_to_index(node_type)\n",
    "\n",
    "    def node_types_to_indices(self, node_types):\n",
    "        \"\"\"Convert list of string representations into list of integer indices.\"\"\"\n",
    "        return [self.node_type_to_index(node_type) for node_type in node_types]\n",
    "\n",
    "    def node_types_to_multi_hot(self, node_types):\n",
    "        \"\"\"Convert between string representation to multi hot encoding of correct node types.\n",
    "\n",
    "        Note: implemented here for backwards compatibility only.\n",
    "        \"\"\"\n",
    "        correct_indices = self.node_types_to_indices(node_types)\n",
    "        multihot = np.zeros(shape=(self.num_node_types,), dtype=np.float32)\n",
    "        for idx in correct_indices:\n",
    "            multihot[idx] = 1.0\n",
    "        return multihot\n",
    "    \n",
    "    def node_type_to_index(self, node_type):\n",
    "        motif_node_type_index = self._motif_to_node_type_index.get(node_type)\n",
    "\n",
    "        if motif_node_type_index is not None:\n",
    "            return motif_node_type_index\n",
    "        else:\n",
    "            return self._atom_type_featuriser.type_name_to_index(node_type)\n",
    "    \n",
    "    def load_metadata(self):\n",
    "        metadata_file_path = os.path.join(self._raw_moler_trace_dataset_parent_folder, 'metadata.pkl.gz')\n",
    "        \n",
    "        with gzip.open(metadata_file_path, 'rb') as f:\n",
    "             self._metadata = pickle.load(f)\n",
    "        \n",
    "        self._atom_type_featuriser = next(\n",
    "            featuriser\n",
    "            for featuriser in self._metadata[\"feature_extractors\"]\n",
    "            if featuriser.name == \"AtomType\"\n",
    "        )\n",
    "        \n",
    "        self._node_type_index_to_string = self._atom_type_featuriser.index_to_atom_type_map.copy()\n",
    "        self._motif_vocabulary = self.metadata.get(\"motif_vocabulary\")\n",
    "\n",
    "        if self._motif_vocabulary is not None:\n",
    "            self._motif_to_node_type_index = get_motif_type_to_node_type_index_map(\n",
    "                motif_vocabulary=self._motif_vocabulary,\n",
    "                num_atom_types=len(self._node_type_index_to_string),\n",
    "            )\n",
    "\n",
    "            for motif, node_type in self._motif_to_node_type_index.items():\n",
    "                self._node_type_index_to_string[node_type] = motif\n",
    "        else:\n",
    "            self._motif_to_node_type_index = {}\n",
    "        \n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Convert raw generation traces into individual .pt files for each of the trace steps.\"\"\"\n",
    "        # only call process if it was not called before\n",
    "        if self.processed_file_names_size > 0:\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            for pkl_file_path in self.raw_file_names:\n",
    "                generation_steps = self._convert_data_shard_to_list_of_trace_steps(pkl_file_path)\n",
    "                \n",
    "                for molecule_idx, molecule_gen_steps in generation_steps:\n",
    "                    \n",
    "                    for step_idx, step in enumerate(molecule_gen_steps):\n",
    "                        file_name = f'{pkl_file_path.split(\"/\")[-1].split(\".\")[0]}_mol_{molecule_idx}_step_{step_idx}.pt'\n",
    "                        file_path = os.path.join(self._output_pyg_trace_dataset_parent_folder, self._split, file_name)\n",
    "                        torch.save(step, file_path)\n",
    "                        print(f'Processing {molecule_idx}, step {step_idx}')\n",
    "            print(f'{self.processed_file_names_size} files generated')         \n",
    "            \n",
    "\n",
    "    def _convert_data_shard_to_list_of_trace_steps(self, pkl_file_path):\n",
    "        # TODO: multiprocessing to speed this up\n",
    "        generation_steps = []\n",
    "        \n",
    "        with gzip.open(pkl_file_path, 'rb') as f:\n",
    "            molecules = pickle.load(f)\n",
    "            for molecule_idx, molecule in enumerate(molecules): \n",
    "                generation_steps += [(molecule_idx, self._extract_generation_steps(molecule))]\n",
    "        \n",
    "        return generation_steps\n",
    "            \n",
    "    def _extract_generation_steps(self, molecule):\n",
    "        \"\"\"Packages each generation step of each molecule into a pyg Data object.\"\"\"\n",
    "        molecule_gen_steps = []\n",
    "        molecule_property_values = dict(molecule.graph_property_values)\n",
    "        for gen_step in molecule:\n",
    "            gen_step_features = {}\n",
    "            gen_step_features['x'] = gen_step.partial_node_features\n",
    "            gen_step_features['focus_node'] = gen_step.focus_node\n",
    "\n",
    "            # have an edge type attribute to tell apart each of the 3 bond types\n",
    "            edge_indexes = []\n",
    "            edge_types= []\n",
    "            for i, adj_list in enumerate(gen_step.partial_adjacency_lists):\n",
    "                if len(adj_list) != 0:\n",
    "                    edge_index = torch.tensor(adj_list).T\n",
    "                    edge_indexes += [edge_index]\n",
    "                    edge_types += [i]*len(adj_list)\n",
    "\n",
    "            gen_step_features['edge_index'] = torch.cat(edge_indexes, 1) if len(edge_indexes) > 0 else torch.tensor(edge_indexes)\n",
    "            gen_step_features['edge_type'] = torch.tensor(edge_types)\n",
    "            gen_step_features['correct_edge_choices'] = gen_step.correct_edge_choices\n",
    "\n",
    "            num_correct_edge_choices = np.sum(gen_step.correct_edge_choices)\n",
    "            gen_step_features['num_correct_edge_choices'] = num_correct_edge_choices\n",
    "            gen_step_features['stop_node_label'] = int(num_correct_edge_choices == 0)\n",
    "            gen_step_features['valid_edge_choices'] = gen_step.valid_edge_choices\n",
    "            gen_step_features[\"correct_edge_types\"] = gen_step.correct_edge_types\n",
    "            gen_step_features[\"partial_node_categorical_features\"] = gen_step.partial_node_categorical_features\n",
    "            if gen_step.correct_attachment_point_choice is not None:\n",
    "                gen_step_features[\"correct_attachment_point_choice\"] = list(gen_step.valid_attachment_point_choices).index(gen_step.correct_attachment_point_choice)\n",
    "            else:\n",
    "                gen_step_features[\"correct_attachment_point_choice\"] = []\n",
    "            gen_step_features[\"valid_attachment_point_choices\"] = gen_step.valid_attachment_point_choices\n",
    "\n",
    "            # And finally, the correct node type choices. Here, we have an empty list of\n",
    "            # correct choices for all steps where we didn't choose a node, so we skip that:\n",
    "            if gen_step.correct_node_type_choices is not None:\n",
    "                gen_step_features[\"correct_node_type_choices\"] = self.node_types_to_multi_hot(gen_step.correct_node_type_choices)\n",
    "            else:\n",
    "                gen_step_features[\"correct_node_type_choices\"] = []\n",
    "            gen_step_features['correct_first_node_type_choices'] = self.node_types_to_multi_hot(molecule.correct_first_node_type_choices)\n",
    "\n",
    "            # Add graph_property_values\n",
    "            gen_step_features = {**gen_step_features, **molecule_property_values}\n",
    "        \n",
    "            molecule_gen_steps += [gen_step_features]\n",
    "        molecule_gen_steps = self._to_tensor_moler(molecule_gen_steps)\n",
    "        return [Data(**step) for step in molecule_gen_steps]\n",
    "    \n",
    "    def _to_tensor_moler(self, molecule_gen_steps):\n",
    "        for i in range(len(molecule_gen_steps)):\n",
    "            for k,v in molecule_gen_steps[i].items():\n",
    "                molecule_gen_steps[i][k] = torch.tensor(molecule_gen_steps[i][k])\n",
    "        return molecule_gen_steps\n",
    "        \n",
    "    def len(self):\n",
    "        return self.processed_file_names_size\n",
    "\n",
    "    def get(self, idx):\n",
    "        file_path = self.processed_file_names[idx]\n",
    "        data = torch.load(file_path)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ece8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MolerDataset(\n",
    "    root = '/data/ongh0068', \n",
    "    raw_moler_trace_dataset_parent_folder = '/data/ongh0068/l1000/trace_playground',\n",
    "    output_pyg_trace_dataset_parent_folder = '/data/ongh0068/l1000/pyg_output_playground',\n",
    "    split = 'train',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1f3f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolerDataset(2384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20fae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=False, follow_batch = [\n",
    "    'correct_edge_choices',\n",
    "    'correct_edge_types',\n",
    "    'valid_edge_choices',\n",
    "    'valid_attachment_point_choices',\n",
    "    'correct_attachment_point_choice',\n",
    "    'correct_node_type_choices'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e604534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([126, 32])\n",
      "edge_index: torch.Size([2, 212])\n",
      "focus_node: torch.Size([16])\n",
      "edge_type: torch.Size([212])\n",
      "correct_edge_choices: torch.Size([53])\n",
      "correct_edge_choices_batch: torch.Size([53])\n",
      "correct_edge_choices_ptr: torch.Size([17])\n",
      "num_correct_edge_choices: torch.Size([16])\n",
      "stop_node_label: torch.Size([16])\n",
      "valid_edge_choices: torch.Size([53, 2])\n",
      "valid_edge_choices_batch: torch.Size([53])\n",
      "valid_edge_choices_ptr: torch.Size([17])\n",
      "correct_edge_types: torch.Size([9, 3])\n",
      "correct_edge_types_batch: torch.Size([9])\n",
      "correct_edge_types_ptr: torch.Size([17])\n",
      "partial_node_categorical_features: torch.Size([126])\n",
      "correct_attachment_point_choice: torch.Size([0])\n",
      "correct_attachment_point_choice_batch: torch.Size([0])\n",
      "correct_attachment_point_choice_ptr: torch.Size([17])\n",
      "valid_attachment_point_choices: torch.Size([0])\n",
      "valid_attachment_point_choices_batch: torch.Size([0])\n",
      "valid_attachment_point_choices_ptr: torch.Size([17])\n",
      "correct_node_type_choices: torch.Size([1112])\n",
      "correct_node_type_choices_batch: torch.Size([1112])\n",
      "correct_node_type_choices_ptr: torch.Size([17])\n",
      "correct_first_node_type_choices: torch.Size([2224])\n",
      "sa_score: torch.Size([16])\n",
      "clogp: torch.Size([16])\n",
      "mol_weight: torch.Size([16])\n",
      "qed: torch.Size([16])\n",
      "bertz: torch.Size([16])\n",
      "batch: torch.Size([126])\n",
      "ptr: torch.Size([17])\n"
     ]
    }
   ],
   "source": [
    "def pprint_pyg_obj(batch):\n",
    "    for key in vars(batch)['_store'].keys():\n",
    "        if key.startswith('_'):\n",
    "            continue\n",
    "        print(f'{key}: {batch[key].shape}')\n",
    "for batch in loader:\n",
    "    pprint_pyg_obj(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77d5b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some information out from the dataset:\n",
    "next_node_type_distribution = dataset.metadata.get(\"train_next_node_type_distribution\")\n",
    "atom_type_nums = [\n",
    "    next_node_type_distribution[dataset.node_type_index_to_string[type_idx]]\n",
    "    for type_idx in range(dataset.num_node_types)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb9effa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 16,  16,  16,  16,  16,  16,  16,  16, 129,  16,  16,  16,  16, 129,\n",
       "         16,  16,  16,  16, 129, 129,  16,  16,  16,  16, 129, 129,  16,  16,\n",
       "         16,  16, 129, 129, 129,  16,  16,  16,  16, 129, 129, 129,  16,  16,\n",
       "         16,  16, 129, 129, 129, 129,  16,  16,  16,  16, 129, 129, 129, 129,\n",
       "         16,  16,  16,  16, 129, 129, 129, 129, 129,  16,  16,  16,  16, 129,\n",
       "        129, 129, 129, 129,  16,  16,  16,  16, 129, 129, 129, 129, 129, 129,\n",
       "         16,  16,  16,  16, 129, 129, 129, 129, 129, 129,  16,  16,  16,  16,\n",
       "        129, 129, 129, 129, 129, 129,  16,  16,  16,  16, 129, 129, 129, 129,\n",
       "        129, 129, 131,  16,  16,  16,  16, 129, 129, 129, 129, 129, 129, 131])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.partial_node_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molecule_generation.utils.training_utils import get_class_balancing_weights\n",
    "\n",
    "class BaseModel(torch.nn.Module):\n",
    "    def __init__(self, params, dataset):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self._init_params(params, dataset)\n",
    "        self._motif_aware_embedding_layer = Embedding(params['motif_aware_embedding'])\n",
    "        self._encoder_gnn = FullGraphEncoder(params['encoder_gnn'])\n",
    "        self._decoder_gnn = PartialGraphEncoder(params['decoder_gnn'])\n",
    "        self._decoder_mlp = MLPDecoder(params['decoderMLP'])\n",
    "        \n",
    "        \n",
    "               \n",
    "    def _init_params(self, params, dataset):\n",
    "        \"\"\"\n",
    "        Initialise class weights for next node prediction and placefolder for\n",
    "        motif/node embeddings.\n",
    "        \"\"\"\n",
    "        self._latent_repr_dim = params[\"latent_repr_size\"]\n",
    "        # Get some information out from the dataset:\n",
    "        next_node_type_distribution = dataset.metadata.get(\"train_next_node_type_distribution\")\n",
    "        class_weight_factor = self._params.get(\"node_type_predictor_class_loss_weight_factor\", 0.0)\n",
    "        \n",
    "        if not (0.0 <= class_weight_factor <= 1.0):\n",
    "            raise ValueError(\n",
    "                f\"Node class loss weight node_classifier_class_loss_weight_factor must be in [0,1], but is {class_weight_factor}!\"\n",
    "            )\n",
    "        if class_weight_factor > 0:\n",
    "            atom_type_nums = [\n",
    "                next_node_type_distribution[dataset.node_type_index_to_string[type_idx]]\n",
    "                for type_idx in range(dataset.num_node_types)\n",
    "            ]\n",
    "            atom_type_nums.append(next_node_type_distribution[\"None\"])\n",
    "\n",
    "            self.class_weights = get_class_balancing_weights(\n",
    "                class_counts=atom_type_nums, class_weight_factor=class_weight_factor\n",
    "            )\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "            \n",
    "        motif_vocabulary = dataset.metadata.get(\"motif_vocabulary\")\n",
    "        self._uses_motifs = motif_vocabulary is not None\n",
    "\n",
    "        self._node_categorical_num_classes = dataset.node_categorical_num_classes\n",
    "        \n",
    "        \n",
    "        if self.uses_categorical_features:\n",
    "            if \"categorical_features_embedding_dim\" in self._params:\n",
    "                self._node_categorical_features_embedding = None\n",
    "        \n",
    "    @property\n",
    "    def uses_motifs(self):\n",
    "        return self._uses_motifs\n",
    "\n",
    "    @property\n",
    "    def uses_categorical_features(self):\n",
    "        return self._node_categorical_num_classes is not None\n",
    "\n",
    "    @property\n",
    "    def decoder(self):\n",
    "        return self._decoder\n",
    "\n",
    "    @property\n",
    "    def encoder(self):\n",
    "        return self._encoder\n",
    "    \n",
    "    @property\n",
    "    def motif_aware_embedding_layer(self):\n",
    "        return self._motif_aware_embedding_layer\n",
    "    \n",
    "    @property\n",
    "    def latent_dim(self):\n",
    "        return self._latent_repr_dim\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Obtain node embeddings \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Forward pass through encoder\n",
    "        latent_repr = self.encoder(input)\n",
    "        \n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        node_type_logits, edge_type_logits, edge_type_logits, attachment_point_selection_logits = self.decoder(latent_repr)\n",
    "        \n",
    "        \n",
    "        # NOTE: loss computation will be done in lightning module\n",
    "        \n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        return x\n",
    "#     def _compute_decoder_loss_and_metrics(\n",
    "#         self, batch_features, task_output, batch_labels\n",
    "#     ) -> Tuple[tf.Tensor, MoLeRDecoderMetrics]:\n",
    "\n",
    "#         decoder_metrics = self.decoder.compute_metrics(\n",
    "#             batch_features=batch_features, batch_labels=batch_labels, task_output=task_output\n",
    "#         )\n",
    "\n",
    "#         total_loss = (\n",
    "#             self._params[\"node_classification_loss_weight\"]\n",
    "#             * decoder_metrics.node_classification_loss\n",
    "#             + self._params[\"first_node_classification_loss_weight\"]\n",
    "#             * decoder_metrics.first_node_classification_loss\n",
    "#             + self._params[\"edge_selection_loss_weight\"] * decoder_metrics.edge_loss\n",
    "#             + self._params[\"edge_type_loss_weight\"] * decoder_metrics.edge_type_loss\n",
    "#         )\n",
    "\n",
    "#         if self.uses_motifs:\n",
    "#             total_loss += (\n",
    "#                 self._params[\"attachment_point_selection_weight\"]\n",
    "#                 * decoder_metrics.attachment_point_selection_loss\n",
    "#             )\n",
    "\n",
    "#         return total_loss, decoder_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd147f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4c98cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(torch.nn.Module):\n",
    "    \"\"\"For constructing graph level embedding during encoder step\"\"\"\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        # torch.manual_seed(12345)\n",
    "        self.conv1 = GATConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = x.leaky_relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = x.leaky_relu()\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        x = \n",
    "        return x\n",
    "\n",
    "\n",
    "class PartialGraphEncoder(torch.nn.Module):\n",
    "    \"\"\"For constructing graph level embedding during decoder steps\"\"\"\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(PartialGraphEncoder, self).__init__()\n",
    "        # torch.manual_seed(12345)\n",
    "        self.conv1 = GATConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        return x\n",
    "  \n",
    "\n",
    "class PickAtomOrMotifMLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    For choosing an atom/motif out of the motif vocabulary\n",
    "    Notes:\n",
    "    Softmax layer at the end with \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, motif_vocabulary, latent_vector_dim, hidden_channels=256):\n",
    "        super(PickAtomOrMotifMLP, self).__init__()\n",
    "        self.hidden_layer1 = Linear(latent_vector_dim, hidden_channels)\n",
    "        self.hidden_layer2 = Linear(hidden_channels, len(motif_vocabulary) + 1) # add 1 for <END OF GENERATION TOKEN>\n",
    "        self.activation = torch.Softmax\n",
    "        \n",
    "    def forward(self, latent_vector, partial_graph_embedding):\n",
    "        x = self.hidden_layer1(latent_vector)\n",
    "        x = self.hidden_layer2(x)\n",
    "        return self.activation(x)\n",
    "        \n",
    "\n",
    "class PickAttachmentMLP(torch.nn.Module):\n",
    "    def __init__(self, motif_dictionary, hidden_channels):\n",
    "        super(PickAttachmentMLP, self).__init__()\n",
    "        pass\n",
    "    def forward(self, latent_vector, partial_graph_embedding):\n",
    "        pass\n",
    "\n",
    "class PickBond(torch.nn.Module):\n",
    "    def __init__(self, motif_dictionary, hidden_channels):\n",
    "        super(PickAttachmentMLP, self).__init__()\n",
    "        pass\n",
    "    def forward(self, latent_vector, partial_graph_embedding):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776f10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5585c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849029d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b9c7059",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "1. Implement the learned aggregation function in Moler Paper by subclassing MessagePassing layer \n",
    "2. Change the init function of the encoder to take in the relevant hyperparameters from the `moler_vae` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f28cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
