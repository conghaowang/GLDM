model:
  base_learning_rate: 5.0e-05
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    linear_start: 0.00085
    linear_end: 0.012
    num_timesteps_cond: 1
    log_every_t: 50
    timesteps: 200
    first_stage_key: image
    cond_stage_key: gene_expressions
    image_size: 512
    channels: 1
    cond_stage_trainable: False
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_factor: 1 #0.18215
    use_ema: False
    parameterization: eps

  first_stage_config:
    target: model.BaseModel
    model_type: vae
    using_lincs: True
    ckpt_path: /data/conghao001/FYP/DrugDiscovery/first_stage_models/2023-03-11_23_33_36.921147/epoch=07-val_loss=0.60.ckpt
  
  cond_stage_config:
    params: 
      dim: 979
      key: gene_expressions

  unet_config:
    target: ldm.modules.diffusionmodules.openaimodel.UNetModel
    params:
      use_spatial_transformer: true
      image_size: 512
      in_channels: 1
      out_channels: 1
      model_channels: 64
      dims: 1 
      attention_resolutions:
      # note: this isn\t actually the resolution but
      # the downsampling factor, i.e. this corresnponds to
      # attention on spatial resolution 8,16,32, as the
      # spatial reolution of the latents is 64 for f4
      - 4
      - 2
      num_res_blocks: 1
      channel_mult:
      - 1
      - 2
      - 3
      context_dim: 979
      num_head_channels: 8